{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import utils\n",
    "import seaborn as sns\n",
    "import importlib\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing as mp\n",
    "import importlib\n",
    "\n",
    "path_figs = \"./Figs/\"\n",
    "\n",
    "# path = \"./SL3/SL3\"\n",
    "path = \"./sh4/\"\n",
    "\n",
    "path_misc = \"./sh4_miscs/\"\n",
    "\n",
    "fingers = [0, 1, 2, 3, 4]\n",
    "\n",
    "iti = 500\n",
    "\n",
    "total_sub_num = 40\n",
    "\n",
    "subjs_ids = {\n",
    "    'BH', 'BI2', 'CBC', 'CD', 'CES', 'CLD', 'CM', 'CMM', 'CNB', 'CNN', 'CS', 'CWT', 'CZE', 'DH',\n",
    "    'IL', 'KA', 'KF', 'KQ', 'MAK', 'MDT', 'MDX', 'MEW', 'MGC', 'MHK', 'MIB', 'MIE', 'MIL', 'MNI',\n",
    "    'MOH', 'MOT', 'MTS', 'MTS2', 'MUU', 'MZT', 'QQ', 'TE', 'TI', 'UC', 'UO', 'ZQ', 'LI'\n",
    "}\n",
    "\n",
    "seq_dict = {\n",
    "    'G1': {\n",
    "        'aligned': [1, 2, 4], \n",
    "        'unaligned': [3, 6, 7],\n",
    "        'control': [5]\n",
    "    } ,\n",
    "    'G2': {\n",
    "        'aligned': [3, 6, 7],\n",
    "        'unaligned': [1, 2, 4],\n",
    "        'control': [5]\n",
    "    }\n",
    "\n",
    "}\n",
    "\n",
    "# subjs_ids = {\n",
    "#     'BH', 'BI2', 'CBC', 'CD', 'CES', 'CLD', 'CM', 'CMM', 'CNB', 'CNN', 'CS', 'CWT', 'CZE', 'DH',\n",
    "#     'IL', 'KA', 'KF', 'KQ', 'MAK', 'MDT', 'MDX', 'MEW', 'MGC', 'MHK', 'MIB', 'MIE', 'MIL', 'MNI',\n",
    "#     'MOH', 'MOT', 'MTS', 'MTS2', 'MUU', 'MZT', 'QQ', 'TE', 'TI', 'UC', 'UO', 'ZQ'\n",
    "# }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjs = pd.concat(utils.read_dat_files_subjs_list())\n",
    "utils.add_IPI(subjs)\n",
    "subjs.sort_values(by = ['SubNum', 'BN', 'TN'], inplace=True)\n",
    "subjs = subjs.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing duplicates from subjs\n",
    "subjs = subjs.drop_duplicates(subset=['SubNum', 'BN', 'TN'], keep='last').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_blocks_per_subject = subjs.groupby('SubNum')['BN'].nunique()\n",
    "unique_blocks_per_subject\n",
    "# flag subjects with 200 BN as control subjects in subjs\n",
    "control_subjs = unique_blocks_per_subject[unique_blocks_per_subject == 200].index\n",
    "control_subjs\n",
    "subjs['control'] = subjs['SubNum'].apply(lambda x: x in control_subjs)\n",
    "\n",
    "# discard subjects with 207 unique blocks\n",
    "discard_subjs = unique_blocks_per_subject[unique_blocks_per_subject == 207].index\n",
    "discard_subjs\n",
    "subjs = subjs[~ subjs['SubNum'].isin(discard_subjs)].reset_index(drop = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_subjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discard_subjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_dict = {\n",
    "    \"G1\": {\n",
    "        \"A\": \"32\",\n",
    "        \"B\": \"34\",\n",
    "        \"C\": \"113\",\n",
    "        \"D\": \"123\",\n",
    "        \"E\": \"321\",\n",
    "        \"F\": \"343\",\n",
    "        \"G\": \"353\",\n",
    "        \"H\": \"435\",\n",
    "        \"I\": \"443\",\n",
    "        \"J\": \"512\",\n",
    "        \"K\": \"513\",\n",
    "    },\n",
    "    \"G2\": {\n",
    "        \"A\": \"12\",\n",
    "        \"B\": \"43\",\n",
    "        \"C\": \"123\",\n",
    "        \"D\": \"134\",\n",
    "        \"E\": \"135\",\n",
    "        \"F\": \"235\",\n",
    "        \"G\": \"321\",\n",
    "        \"H\": \"332\",\n",
    "        \"I\": \"341\",\n",
    "        \"J\": \"351\",\n",
    "        \"K\": \"551\",\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "sub_group = {}\n",
    "for subnum, subjs_data in subjs.groupby('SubNum'):\n",
    "    if subjs_data['control'].iloc[0]:\n",
    "        continue\n",
    "    # print(subnum)\n",
    "    # print(subjs_data[['cueC', 'cueP']].iloc[126])\n",
    "    # print(subjs_data['cueC'].iloc[126])\n",
    "    # print(subjs_data['cueP'].iloc[126])\n",
    "    #based on the cueC and cueP values, we can determine the group based on the chunk_dict\n",
    "    for group, chunks in chunk_dict.items():\n",
    "        if chunks[subjs_data['cueC'].iloc[126]] == subjs_data['cueP'].iloc[126]:\n",
    "            # print(group)\n",
    "            sub_group[subnum] = group\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specific_sequences = np.arange(1,8)\n",
    "induction_blocks_treatment = np.arange(1, 62)\n",
    "optimization_blocks_treatment = np.arange(62, 188)\n",
    "memory_optimization_blocks_treatment = np.arange(62, 138)\n",
    "\n",
    "induction_blocks_control = np.arange(1, 52)\n",
    "optimization_blocks_control = np.arange(52, 178)\n",
    "memory_topimization_blocks_control = np.arange(52, 128)\n",
    "subjs_seq = subjs[subjs['seqNumb'].isin(specific_sequences)].reset_index(drop = True)\n",
    "\n",
    "# for control subjects, select induction and optimization blocks\n",
    "subjs_seq_control = subjs_seq[subjs_seq['control']].reset_index(drop=True)\n",
    "subjs_seq_control_induction = subjs_seq_control[subjs_seq_control['BN'].isin(induction_blocks_control)].reset_index(drop=True)\n",
    "subjs_seq_control_optimization = subjs_seq_control[subjs_seq_control['BN'].isin(optimization_blocks_control)].reset_index(drop=True)\n",
    "\n",
    "# for treatment subjects, select induction and optimization blocks\n",
    "subjs_seq_treatment = subjs_seq[~subjs_seq['control']]\n",
    "# add group column to subjs_seq_treatment based on sub_group\n",
    "subjs_seq_treatment['group'] = subjs_seq_treatment['SubNum'].map(sub_group)\n",
    "# based on group column and seq_dict, add a column to subjs_seq_treatment to indicate the type of sequence\n",
    "subjs_seq_treatment['seq_type'] = subjs_seq_treatment.apply(utils.seq_type_mapping, axis=1)\n",
    "subjs_seq_treatment = subjs_seq_treatment.reset_index(drop=True)\n",
    "\n",
    "subjs_seq_treatment_induction = subjs_seq_treatment[subjs_seq_treatment['BN'].isin(induction_blocks_treatment)].reset_index(drop=True)\n",
    "subjs_seq_treatment_optimization = subjs_seq_treatment[subjs_seq_treatment['BN'].isin(optimization_blocks_treatment)].reset_index(drop=True)\n",
    "\n",
    "subjs_seq_control_optimization['rep'] = subjs_seq_control_optimization.groupby(['SubNum', 'BN'])['seqNumb'].shift(1) == subjs_seq_control_optimization['seqNumb']\n",
    "subjs_seq_control_optimization['rep'] = subjs_seq_control_optimization['rep'].fillna(False)\n",
    "subjs_seq_treatment_optimization['rep'] = subjs_seq_treatment_optimization.groupby(['SubNum', 'BN'])['seqNumb'].shift(1) == subjs_seq_treatment_optimization['seqNumb']\n",
    "subjs_seq_treatment_optimization['rep'] = subjs_seq_treatment_optimization['rep'].fillna(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(subjs['SubNum'].nunique())\n",
    "print(subjs_seq_control['SubNum'].nunique())\n",
    "print(subjs_seq_treatment[subjs_seq_treatment['group'] == 'G1']['SubNum'].nunique())\n",
    "print(subjs_seq_treatment[subjs_seq_treatment['group'] == 'G2']['SubNum'].nunique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subj_id in subjs_ids:\n",
    "    print(len(subjs_seq_treatment_optimization[subjs_seq_treatment_optimization['SubNum'] == subj_id]))\n",
    "for subj_id in subjs_ids:\n",
    "    print(len(subjs_seq_control_optimization[subjs_seq_control_optimization['SubNum'] == subj_id]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subjs_presses = utils.finger_melt(subjs)\n",
    "# subjs_presses_seq = utils.finger_melt(subjs_seq)\n",
    "# subjs_presses_seq_treatment = utils.finger_melt_treatment(subjs_seq_treatment)\n",
    "# subjs_presses_seq_control = utils.finger_melt(subjs_seq_control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subjs_presses.to_csv(path_misc + \"subjs_presses.csv\", index=False)\n",
    "# subjs_presses_seq.to_csv(path_misc + \"subjs_presses_seq.csv\", index=False)\n",
    "# subjs_presses_seq_treatment.to_csv(path_misc + \"subjs_presses_seq_treatment.csv\", index=False)\n",
    "# subjs_presses_seq_control.to_csv(path_misc + \"subjs_presses_seq_control.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjs_presses = pd.read_csv(path_misc + \"subjs_presses.csv\")\n",
    "subjs_presses_seq = pd.read_csv(path_misc + \"subjs_presses_seq.csv\")\n",
    "subjs_presses_seq_treatment = pd.read_csv(path_misc + \"subjs_presses_seq_treatment.csv\")\n",
    "subjs_presses_seq_control = pd.read_csv(path_misc + \"subjs_presses_seq_control.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjs_seq['MT'].sort_values()[-10:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjs.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjs['iti']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(subjs_seq['MT'])\n",
    "plt.axvline(subjs_seq['MT'].median(), 0, 1000, color='red')\n",
    "plt.xlim(0, 10000)\n",
    "print('MT median:', subjs_seq['MT'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(subjs_seq['IPI0'])\n",
    "plt.axvline(subjs_seq['IPI0'].median(), 0, 1000, color='red')\n",
    "plt.xlim(0, 10000)\n",
    "print('RT median:', subjs_seq['IPI0'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = subjs_seq.sort_values(by = 'IPI0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "cmap = cm.Pastel1\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "\n",
    "day_change_blocks = [17, 39, 50, 61, 74, 87, 99, 112, 124, 137, 150, 162, 175, 187]\n",
    "\n",
    "subjs_seq_treatment_correct = utils.remove_error_trials(subjs_seq_treatment)\n",
    "\n",
    "session_grouped = subjs_seq_treatment_correct.groupby(['BN', 'SubNum']).agg({\n",
    "    'MT': 'median'\n",
    "}).reset_index()\n",
    "       \n",
    "\n",
    "session_grouped = session_grouped.groupby(['BN']).agg({\n",
    "    'MT': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "plt.plot(session_grouped['BN'], session_grouped['MT'], marker = 'o', color = cmap(0))\n",
    "\n",
    "\n",
    "for day_change in day_change_blocks:\n",
    "    plt.axvline(day_change + 0.5, linestyle = 'dotted', color = 'gray')\n",
    "\n",
    "plt.title('ET')\n",
    "\n",
    "plt.xlabel('Block')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "cmap = cm.Pastel1\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "\n",
    "day_change_blocks = [17, 39, 50, 61, 74, 87, 99, 112, 124, 137, 150, 162, 175, 187]\n",
    "\n",
    "\n",
    "session_grouped = subjs_seq_treatment.groupby(['BN', 'SubNum']).agg({\n",
    "    'isError': 'sum', \n",
    "    'TN': 'count'\n",
    "}).reset_index()\n",
    "session_grouped['error_rate'] = session_grouped['isError'] / session_grouped['TN']\n",
    "       \n",
    "\n",
    "session_grouped = session_grouped.groupby(['BN']).agg({\n",
    "    'error_rate': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "plt.plot(session_grouped['BN'], session_grouped['error_rate'], marker = 'o', color = cmap(0))\n",
    "\n",
    "\n",
    "for day_change in day_change_blocks:\n",
    "    plt.axvline(day_change + 0.5, linestyle = 'dotted', color = 'gray')\n",
    "\n",
    "plt.title('Error Rate')\n",
    "\n",
    "plt.xlabel('Block')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from natsort import index_natsorted\n",
    "from matplotlib import cm\n",
    "# fig, axs = plt.subplots(len(windowSizes), figsize= (20,15))\n",
    "cmap = cm.cividis\n",
    "capsize = 5\n",
    "\n",
    "\n",
    "data = utils.remove_error_trials(subjs_presses_seq_treatment)\n",
    "\n",
    "data = data[data['BN'].isin(induction_blocks_treatment)]\n",
    "\n",
    "for idx, (alignment, alignment_data) in enumerate(data.groupby('seq_type')):\n",
    "    if alignment == 'control':\n",
    "        continue\n",
    "\n",
    "    finger_agg = alignment_data.groupby(['SubNum', 'IPI_Number']).agg({\n",
    "        'IPI_Value': 'median'\n",
    "    }).reset_index()\n",
    "\n",
    "\n",
    "    finger_agg_rand = finger_agg.groupby(['IPI_Number']).agg({\n",
    "                    'IPI_Value': ['mean', 'sem']\n",
    "                }).reset_index()\n",
    "\n",
    "    finger_agg_rand = finger_agg_rand.iloc[index_natsorted(finger_agg_rand['IPI_Number'])].reset_index(drop=True)\n",
    "    \n",
    "    #ignore IPI0\n",
    "    finger_agg_rand = finger_agg_rand[finger_agg_rand['IPI_Number'] != 'IPI0']\n",
    "\n",
    "    # plt.errorbar(finger_agg_rand['IPI_Number'], finger_agg_rand['IPI_Value']['mean'], yerr = finger_agg_rand['IPI_Value']['sem'], color = 'black' capsize = capsize, alpha = 0.2)\n",
    "    plt.errorbar(finger_agg_rand['IPI_Number'], finger_agg_rand['IPI_Value']['mean'], yerr = finger_agg_rand['IPI_Value']['sem'], capsize = capsize, color=cmap(idx * 100), label = alignment)\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.title('Induction')\n",
    "plt.ylim(100, 600)\n",
    "\n",
    "    # axs[idx].set_title(f'window = {window}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from natsort import index_natsorted\n",
    "\n",
    "# fig, axs = plt.subplots(len(windowSizes), figsize= (20,15))\n",
    "cmap = cm.cividis\n",
    "capsize = 5\n",
    "\n",
    "\n",
    "data = utils.remove_error_trials(subjs_presses_seq_treatment)\n",
    "\n",
    "data = data[data['BN'].isin(optimization_blocks_treatment)]\n",
    "\n",
    "for idx, (alignment, alignment_data) in enumerate(data.groupby('seq_type')):\n",
    "    if alignment == 'control':\n",
    "        continue\n",
    "\n",
    "    finger_agg = alignment_data.groupby(['SubNum', 'IPI_Number']).agg({\n",
    "        'IPI_Value': 'median'\n",
    "    }).reset_index()\n",
    "\n",
    "\n",
    "    finger_agg_rand = finger_agg.groupby(['IPI_Number']).agg({\n",
    "                    'IPI_Value': ['mean', 'sem']\n",
    "                }).reset_index()\n",
    "\n",
    "    finger_agg_rand = finger_agg_rand.iloc[index_natsorted(finger_agg_rand['IPI_Number'])].reset_index(drop=True)\n",
    "    \n",
    "    #ignore IPI0\n",
    "    finger_agg_rand = finger_agg_rand[finger_agg_rand['IPI_Number'] != 'IPI0']\n",
    "\n",
    "    # plt.errorbar(finger_agg_rand['IPI_Number'], finger_agg_rand['IPI_Value']['mean'], yerr = finger_agg_rand['IPI_Value']['sem'], color = 'black' capsize = capsize, alpha = 0.2)\n",
    "    plt.errorbar(finger_agg_rand['IPI_Number'], finger_agg_rand['IPI_Value']['mean'], yerr = finger_agg_rand['IPI_Value']['sem'], capsize = capsize, color=cmap(idx * 100), label = alignment)\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.title('Optimization')\n",
    "plt.ylim(100, 600)\n",
    "\n",
    "\n",
    "    # axs[idx].set_title(f'window = {window}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjs_seq.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mov Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# List all files in the path directory and subdirectories\n",
    "all_files = []\n",
    "for root, dirs, files in os.walk(path):\n",
    "    for file in files:\n",
    "        all_files.append(os.path.join(root, file))\n",
    "# all_files = os.listdir(path)\n",
    "\n",
    "# Filter files that contain any of the subjs_ids and have a .dat extension\n",
    "filtered_files = [file for file in all_files if file.endswith('.mov') and any(subj_id in file for subj_id in subjs_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(filtered_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Create a dictionary to hold lists of files for each subject\n",
    "subject_files = defaultdict(list)\n",
    "\n",
    "# Iterate over the filtered files and group them by subject ID\n",
    "for file in filtered_files:\n",
    "    for subj_id in subjs_ids:\n",
    "        if '_' + subj_id + '_' in file:\n",
    "            subject_files[subj_id].append(file)\n",
    "            # break\n",
    "\n",
    "for subj_id, files in subject_files.items():\n",
    "    print(f\"Subject {subj_id} has {len(files)} files\")\n",
    "\n",
    "\n",
    "\n",
    "# # Convert defaultdict to a regular dictionary for easier handling\n",
    "subject_files = dict(subject_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import glob\n",
    "# import os\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# # Directory to save the separate files for each subject\n",
    "# output_dir = path_misc +'output_subjects/'\n",
    "# os.makedirs(output_dir, exist_ok=True)  # Create the directory if it doesn't exist\n",
    "\n",
    "# def movload(fname):\n",
    "#     \"\"\"Loads .mov files given the path.\"\"\"\n",
    "#     with open(fname, 'rt') as fid:\n",
    "#         trials = []\n",
    "#         current_trial = []\n",
    "#         num_columns = None\n",
    "\n",
    "#         for line in fid:\n",
    "#             if line.startswith('T'):\n",
    "#                 # Process trial header\n",
    "#                 if current_trial:\n",
    "#                     trials.append(np.array(current_trial))\n",
    "#                 current_trial = []\n",
    "#                 num_columns = None\n",
    "#             else:\n",
    "#                 # Process trial data\n",
    "#                 line_data = line.strip().split('\\t')\n",
    "#                 if num_columns is None:\n",
    "#                     num_columns = len(line_data)\n",
    "#                 current_trial.append([float(x) for x in line_data])\n",
    "        \n",
    "#         # Append the last trial\n",
    "#         if current_trial:\n",
    "#             trials.append(np.array(current_trial))\n",
    "#     return trials\n",
    "\n",
    "# for subj_id, files in subject_files.items():\n",
    "#     # Create a separate CSV file for each subject\n",
    "#     subject_output_file = os.path.join(output_dir, f'subject_{subj_id}.csv')\n",
    "\n",
    "#     # skip if the file already exists\n",
    "#     if os.path.exists(subject_output_file):\n",
    "#         continue\n",
    "\n",
    "#     if subj_id == 'LI':\n",
    "#         subject_output_file = os.path.join(output_dir, f'subject_IL.csv')\n",
    "#     else:\n",
    "#         # Initialize the subject-specific file with headers\n",
    "#         pd.DataFrame(columns=['state', 'timeReal', 'time', 'force1', 'force2', 'force3', 'force4', 'force5', 'TN', 'BN', 'SubNum']).to_csv(subject_output_file, index=False)\n",
    "    \n",
    "#     for file in tqdm(files):\n",
    "#         filename = os.path.basename(file)\n",
    "#         parts = filename.split('_')\n",
    "\n",
    "#         if len(parts) >= 3:\n",
    "#             subnum = parts[1]\n",
    "#             block_number = int(parts[2].replace('.mov', ''))\n",
    "\n",
    "#             trials = movload(file)\n",
    "#             for trial_idx, trial in enumerate(trials):\n",
    "#                 df = pd.DataFrame(trial, columns=['state', 'timeReal', 'time', 'force1', 'force2', 'force3', 'force4', 'force5'])\n",
    "#                 df['TN'] = trial_idx + 1\n",
    "#                 df['BN'] = block_number\n",
    "#                 df['SubNum'] = 'IL' if subnum == 'LI' else subnum\n",
    "                \n",
    "#                 # Append the data to the subject-specific CSV\n",
    "#                 df.to_csv(subject_output_file, mode='a', header=False, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = path_misc +'output_subjects/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_dir = path_misc +'output_subjects/'\n",
    "# for idx, file in tqdm(enumerate(os.listdir(output_dir))):\n",
    "#     # if idx != 5:\n",
    "#     #     continue\n",
    "\n",
    "#     if file.endswith('.csv') and not file.endswith('_seq.csv'):\n",
    "#         file_path = os.path.join(output_dir, file)\n",
    "#         if os.path.exists(file_path.replace('.csv', '_seq.csv')):\n",
    "#             continue\n",
    "\n",
    "#         print(file_path)\n",
    "#         # Load the data from the CSV file\n",
    "#         subject_data = pd.read_csv(file_path)\n",
    "#         subject_data = subject_data.merge(subjs_seq, on=['SubNum', 'BN', 'TN'], how='inner')\n",
    "#         rank_df = pd.DataFrame(index = subject_data.index)\n",
    "#         subject_data = subject_data.sort_values(by = ['BN', 'TN'])\n",
    "#         subject_data['N'] = subject_data.groupby(['BN', 'TN']).ngroup() + 1\n",
    "\n",
    "#         subject_data_forces_exec = utils.finger_melt_Forces(subject_data)\n",
    "                \n",
    "#         subject_data_forces_exec.to_csv(file_path.replace('.csv', '_seq.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "High RT Trial Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subject_data_forces_exec = pd.read_csv(output_dir + 'subject_CWT_seq.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = subject_data_forces_exec[(subject_data_forces_exec['N'] == 1429)]\n",
    "# # state_changes = x[x['state'].diff() != 0].index\n",
    "# # print(x['board'].unique())\n",
    "\n",
    "# fig = plt.figure(figsize=(15, 5))\n",
    "\n",
    "# for force, data in x.groupby('Force_Number'):\n",
    "#     plt.plot(data['time'], data['Force_Value'], label = force)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # for i in range(1,6):\n",
    "# #     plt.plot(x['time'], x[f'force{i}'], label = i)\n",
    "\n",
    "# state_changes = x[x['state'].diff() != 0].index\n",
    "\n",
    "# state_changes = x.loc[state_changes]['time'].unique()\n",
    "\n",
    "# for change in state_changes:\n",
    "#     plt.axvline(change, color = 'black')\n",
    "\n",
    "# plt.axvline(x['IPI0'].unique(), color = 'red')\n",
    "# print(x['IPI0'].unique())\n",
    "\n",
    "\n",
    "# print(state_changes)\n",
    "\n",
    "\n",
    "# # print(x['seq'].unique())\n",
    "\n",
    "\n",
    "# plt.legend()\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for bn, bndata in subject_data_forces_exec.groupby('BN'):\n",
    "#     for tn, tndata in bndata.groupby('TN'):\n",
    "#         for force, data in tndata.groupby('Force_Number'):\n",
    "#             baseline = data[data['time'] <= 15]['Force_Value'].mean()\n",
    "#             # print(data)\n",
    "#             subject_data_forces_exec.loc[data.index, 'Force_Value'] = data['Force_Value'] - baseline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = subject_data_forces_exec[(subject_data_forces_exec['N'] == 1429)]\n",
    "# # state_changes = x[x['state'].diff() != 0].index\n",
    "# # print(x['board'].unique())\n",
    "\n",
    "# fig = plt.figure(figsize=(15, 5))\n",
    "\n",
    "# for force, data in x.groupby('Force_Number'):\n",
    "#     plt.plot(data['time'], data['Force_Value'], label = force)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # for i in range(1,6):\n",
    "# #     plt.plot(x['time'], x[f'force{i}'], label = i)\n",
    "\n",
    "# state_changes = x[x['state'].diff() != 0].index\n",
    "\n",
    "# state_changes = x.loc[state_changes]['time'].unique()\n",
    "\n",
    "# for change in state_changes:\n",
    "#     plt.axvline(change, color = 'black')\n",
    "\n",
    "# plt.axvline(x['IPI0'].unique(), color = 'red')\n",
    "\n",
    "\n",
    "# print(state_changes)\n",
    "\n",
    "\n",
    "# # print(x['seq'].unique())\n",
    "\n",
    "\n",
    "# plt.legend()\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subjs_force_exec_cut = utils.cut_force(subject_data_forces_exec, 0)\n",
    "# subjs_force_exec_cut_left = utils.cut_force_left(subject_data_forces_exec)\n",
    "# subjs_force_exec_cut_right = utils.cut_force_right(subject_data_forces_exec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_samples = 300\n",
    "# n_samples_left_right = 30\n",
    "# aligned_cut_force = pd.DataFrame(columns=subjs_force_exec_cut.columns)\n",
    "# interpolated_data = []\n",
    "# x_center_interp = np.linspace(0, 1, n_samples)\n",
    "# interval = x_center_interp[1] - x_center_interp[0]\n",
    "# x_right_interp = np.linspace(x_center_interp[-1] + interval, x_center_interp[-1] + interval * n_samples_left_right, n_samples_left_right) - 1\n",
    "# x_left_interp = np.linspace(x_center_interp[0] - interval * n_samples_left_right, x_center_interp[0] - interval, n_samples_left_right) + 1\n",
    "\n",
    "\n",
    "# for sub, subdata in tqdm(subjs_force_exec_cut_left.groupby('SubNum')):\n",
    "#     for bn, bndata in subdata.groupby('BN'):\n",
    "#         for tn, tndata in bndata.groupby('TN'):\n",
    "#             for force, data in tndata.groupby('Force_Number'):\n",
    "#                 warped_force = np.interp(x_left_interp, np.linspace(0,1, len(data)), data['Force_Value'])\n",
    "\n",
    "                \n",
    "#                 interpolated_df = pd.DataFrame({\n",
    "#                     'SubNum': sub,\n",
    "#                     'BN': bn,\n",
    "#                     'TN': tn,\n",
    "#                     'Force_Number': force,\n",
    "#                     'Force_Value': warped_force,\n",
    "#                     'time': x_left_interp  - 1,\n",
    "#                     'state': data['state'].iloc[0],\n",
    "#                     'timeReal': data['timeReal'].iloc[0],\n",
    "#                     'N': data['N'].iloc[0],\n",
    "#                     'seqNumb': data['seqNumb'].iloc[0],\n",
    "#                     'isError': data['isError'].iloc[0],\n",
    "#                     'points': data['points'].iloc[0]\n",
    "#                 })\n",
    "#                 # new_df = pd.concat([new_df, interpolated_df])\n",
    "#                 interpolated_data.append(interpolated_df)\n",
    "\n",
    "\n",
    "# for sub, subdata in tqdm(subjs_force_exec_cut.groupby('SubNum')):\n",
    "#     for bn, bndata in subdata.groupby('BN'):\n",
    "#         for tn, tndata in bndata.groupby('TN'):\n",
    "#             for force, data in tndata.groupby('Force_Number'):\n",
    "#                 warped_force = np.interp(x_center_interp, np.linspace(0,1, len(data)), data['Force_Value'])\n",
    "\n",
    "                \n",
    "#                 interpolated_df = pd.DataFrame({\n",
    "#                     'SubNum': sub,\n",
    "#                     'BN': bn,\n",
    "#                     'TN': tn,\n",
    "#                     'Force_Number': force,\n",
    "#                     'Force_Value': warped_force,\n",
    "#                     'time': x_center_interp,\n",
    "#                     'state': data['state'].iloc[0],\n",
    "#                     'timeReal': data['timeReal'].iloc[0],\n",
    "#                     'N': data['N'].iloc[0],\n",
    "#                     'seqNumb': data['seqNumb'].iloc[0],\n",
    "#                     'isError': data['isError'].iloc[0],\n",
    "#                     'points': data['points'].iloc[0]\n",
    "#                 })\n",
    "#                 # new_df = pd.concat([new_df, interpolated_df])\n",
    "#                 interpolated_data.append(interpolated_df)\n",
    "\n",
    "\n",
    "# for sub, subdata in tqdm(subjs_force_exec_cut_right.groupby('SubNum')):\n",
    "#     for bn, bndata in subdata.groupby('BN'):\n",
    "#         for tn, tndata in bndata.groupby('TN'):\n",
    "#             for force, data in tndata.groupby('Force_Number'):\n",
    "#                 warped_force = np.interp(x_right_interp, np.linspace(0,1, len(data)), data['Force_Value'])\n",
    "                \n",
    "#                 interpolated_df = pd.DataFrame({\n",
    "#                     'SubNum': sub,\n",
    "#                     'BN': bn,\n",
    "#                     'TN': tn,\n",
    "#                     'Force_Number': force,\n",
    "#                     'Force_Value': warped_force,\n",
    "#                     'time': x_right_interp  + 1,\n",
    "#                     'state': data['state'].iloc[0],\n",
    "#                     'timeReal': data['timeReal'].iloc[0],\n",
    "#                     'N': data['N'].iloc[0],\n",
    "#                     'seqNumb': data['seqNumb'].iloc[0],\n",
    "#                     'isError': data['isError'].iloc[0],\n",
    "#                     'points': data['points'].iloc[0]\n",
    "#                 })\n",
    "#                 # new_df = pd.concat([new_df, interpolated_df])\n",
    "#                 interpolated_data.append(interpolated_df)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# aligned_cut_force = pd.concat(interpolated_data, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_force(aligned_cut_force, 1429)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subject_data_forces_exec = pd.read_csv(output_dir + 'subject_CD_seq.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Low RT Trial Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = subject_data_forces_exec[(subject_data_forces_exec['BN'] == 86) & (subject_data_forces_exec['TN'] == 6)]\n",
    "# # state_changes = x[x['state'].diff() != 0].index\n",
    "# # print(x['board'].unique())\n",
    "\n",
    "# fig = plt.figure(figsize=(15, 5))\n",
    "\n",
    "# for force, data in x.groupby('Force_Number'):\n",
    "#     plt.plot(data['time'], data['Force_Value'], label = force)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # for i in range(1,6):\n",
    "# #     plt.plot(x['time'], x[f'force{i}'], label = i)\n",
    "\n",
    "# state_changes = x[x['state'].diff() != 0].index\n",
    "\n",
    "# state_changes = x.loc[state_changes]['time'].unique()\n",
    "\n",
    "# for change in state_changes:\n",
    "#     plt.axvline(change, color = 'black')\n",
    "\n",
    "# plt.axvline(x['IPI0'].unique(), color = 'red')\n",
    "# print(x['IPI0'].unique())\n",
    "\n",
    "\n",
    "# print(state_changes)\n",
    "\n",
    "\n",
    "# # print(x['seq'].unique())\n",
    "\n",
    "\n",
    "# plt.legend()\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = subject_data_forces_exec[(subject_data_forces_exec['N'] == 10)]\n",
    "# # state_changes = x[x['state'].diff() != 0].index\n",
    "# # print(x['board'].unique())\n",
    "\n",
    "# fig = plt.figure(figsize=(15, 5))\n",
    "\n",
    "# for force, data in x.groupby('Force_Number'):\n",
    "#     plt.plot(data['time'], data['Force_Value'], label = force)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # for i in range(1,6):\n",
    "# #     plt.plot(x['time'], x[f'force{i}'], label = i)\n",
    "\n",
    "# state_changes = x[x['state'].diff() != 0].index\n",
    "\n",
    "# state_changes = x.loc[state_changes]['time'].unique()\n",
    "\n",
    "# for change in state_changes:\n",
    "#     plt.axvline(change, color = 'black')\n",
    "\n",
    "# plt.axvline(x['IPI0'].unique(), color = 'red')\n",
    "# print(x['IPI0'].unique())\n",
    "\n",
    "\n",
    "# print(state_changes)\n",
    "\n",
    "\n",
    "# # print(x['seq'].unique())\n",
    "\n",
    "\n",
    "# plt.legend()\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for bn, bndata in subject_data_forces_exec.groupby('BN'):\n",
    "#     for tn, tndata in bndata.groupby('TN'):\n",
    "#         for force, data in tndata.groupby('Force_Number'):\n",
    "#             baseline = data[data['time'] <= 15]['Force_Value'].mean()\n",
    "#             # print(data)\n",
    "#             subject_data_forces_exec.loc[data.index, 'Force_Value'] = data['Force_Value'] - baseline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = subject_data_forces_exec[(subject_data_forces_exec['N'] == 10)]\n",
    "# # state_changes = x[x['state'].diff() != 0].index\n",
    "# # print(x['board'].unique())\n",
    "\n",
    "# fig = plt.figure(figsize=(15, 5))\n",
    "\n",
    "# for force, data in x.groupby('Force_Number'):\n",
    "#     plt.plot(data['time'], data['Force_Value'], label = force)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # for i in range(1,6):\n",
    "# #     plt.plot(x['time'], x[f'force{i}'], label = i)\n",
    "\n",
    "# state_changes = x[x['state'].diff() != 0].index\n",
    "\n",
    "# state_changes = x.loc[state_changes]['time'].unique()\n",
    "\n",
    "# for change in state_changes:\n",
    "#     plt.axvline(change, color = 'black')\n",
    "\n",
    "# plt.axvline(x['IPI0'].unique(), color = 'red')\n",
    "\n",
    "\n",
    "# print(state_changes)\n",
    "\n",
    "\n",
    "# # print(x['seq'].unique())\n",
    "\n",
    "\n",
    "# plt.legend()\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subjs_force_exec_cut = utils.cut_force(subject_data_forces_exec, 0)\n",
    "# subjs_force_exec_cut_left = utils.cut_force_left(subject_data_forces_exec)\n",
    "# subjs_force_exec_cut_right = utils.cut_force_right(subject_data_forces_exec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_force(subjs_force, n):\n",
    "    plt.figure()\n",
    "    x = subjs_force[(subjs_force['N'] == n)]\n",
    "    for force, data in x.groupby('Force_Number'):\n",
    "        plt.plot(data['time'], data['Force_Value'], label = force)\n",
    "    state_changes = x[x['state'].diff() != 0].index\n",
    "    state_changes = x.loc[state_changes]['time'].unique()\n",
    "    for change in state_changes:\n",
    "        plt.axvline(change, color = 'black')\n",
    "\n",
    "    plt.ylim([-0.2, 6])\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_force(subjs_force_exec_cut, 10)\n",
    "# plot_force(subjs_force_exec_cut_left, 10)\n",
    "# plot_force(subjs_force_exec_cut_right, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_samples = 300\n",
    "# n_samples_left_right = 30\n",
    "# aligned_cut_force = pd.DataFrame(columns=subjs_force_exec_cut.columns)\n",
    "# interpolated_data = []\n",
    "# x_center_interp = np.linspace(0, 1, n_samples)\n",
    "# interval = x_center_interp[1] - x_center_interp[0]\n",
    "# x_right_interp = np.linspace(x_center_interp[-1] + interval, x_center_interp[-1] + interval * n_samples_left_right, n_samples_left_right) - 1\n",
    "# x_left_interp = np.linspace(x_center_interp[0] - interval * n_samples_left_right, x_center_interp[0] - interval, n_samples_left_right) + 1\n",
    "\n",
    "\n",
    "# for sub, subdata in tqdm(subjs_force_exec_cut_left.groupby('SubNum')):\n",
    "#     for bn, bndata in subdata.groupby('BN'):\n",
    "#         for tn, tndata in bndata.groupby('TN'):\n",
    "#             for force, data in tndata.groupby('Force_Number'):\n",
    "#                 warped_force = np.interp(x_left_interp, np.linspace(0,1, len(data)), data['Force_Value'])\n",
    "\n",
    "                \n",
    "#                 interpolated_df = pd.DataFrame({\n",
    "#                     'SubNum': sub,\n",
    "#                     'BN': bn,\n",
    "#                     'TN': tn,\n",
    "#                     'Force_Number': force,\n",
    "#                     'Force_Value': warped_force,\n",
    "#                     'time': x_left_interp  - 1,\n",
    "#                     'state': data['state'].iloc[0],\n",
    "#                     'timeReal': data['timeReal'].iloc[0],\n",
    "#                     'N': data['N'].iloc[0],\n",
    "#                     'seqNumb': data['seqNumb'].iloc[0],\n",
    "#                     'isError': data['isError'].iloc[0],\n",
    "#                     'points': data['points'].iloc[0]\n",
    "#                 })\n",
    "#                 # new_df = pd.concat([new_df, interpolated_df])\n",
    "#                 interpolated_data.append(interpolated_df)\n",
    "\n",
    "\n",
    "# for sub, subdata in tqdm(subjs_force_exec_cut.groupby('SubNum')):\n",
    "#     for bn, bndata in subdata.groupby('BN'):\n",
    "#         for tn, tndata in bndata.groupby('TN'):\n",
    "#             for force, data in tndata.groupby('Force_Number'):\n",
    "#                 warped_force = np.interp(x_center_interp, np.linspace(0,1, len(data)), data['Force_Value'])\n",
    "\n",
    "                \n",
    "#                 interpolated_df = pd.DataFrame({\n",
    "#                     'SubNum': sub,\n",
    "#                     'BN': bn,\n",
    "#                     'TN': tn,\n",
    "#                     'Force_Number': force,\n",
    "#                     'Force_Value': warped_force,\n",
    "#                     'time': x_center_interp,\n",
    "#                     'state': data['state'].iloc[0],\n",
    "#                     'timeReal': data['timeReal'].iloc[0],\n",
    "#                     'N': data['N'].iloc[0],\n",
    "#                     'seqNumb': data['seqNumb'].iloc[0],\n",
    "#                     'isError': data['isError'].iloc[0],\n",
    "#                     'points': data['points'].iloc[0]\n",
    "#                 })\n",
    "#                 # new_df = pd.concat([new_df, interpolated_df])\n",
    "#                 interpolated_data.append(interpolated_df)\n",
    "\n",
    "\n",
    "# for sub, subdata in tqdm(subjs_force_exec_cut_right.groupby('SubNum')):\n",
    "#     for bn, bndata in subdata.groupby('BN'):\n",
    "#         for tn, tndata in bndata.groupby('TN'):\n",
    "#             for force, data in tndata.groupby('Force_Number'):\n",
    "#                 warped_force = np.interp(x_right_interp, np.linspace(0,1, len(data)), data['Force_Value'])\n",
    "                \n",
    "#                 interpolated_df = pd.DataFrame({\n",
    "#                     'SubNum': sub,\n",
    "#                     'BN': bn,\n",
    "#                     'TN': tn,\n",
    "#                     'Force_Number': force,\n",
    "#                     'Force_Value': warped_force,\n",
    "#                     'time': x_right_interp  + 1,\n",
    "#                     'state': data['state'].iloc[0],\n",
    "#                     'timeReal': data['timeReal'].iloc[0],\n",
    "#                     'N': data['N'].iloc[0],\n",
    "#                     'seqNumb': data['seqNumb'].iloc[0],\n",
    "#                     'isError': data['isError'].iloc[0],\n",
    "#                     'points': data['points'].iloc[0]\n",
    "#                 })\n",
    "#                 # new_df = pd.concat([new_df, interpolated_df])\n",
    "#                 interpolated_data.append(interpolated_df)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# aligned_cut_force = pd.concat(interpolated_data, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_force(aligned_cut_force, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del interpolated_data\n",
    "# del aligned_cut_force\n",
    "# del subjs_force_exec_cut\n",
    "# del subjs_force_exec_cut_left\n",
    "# del subjs_force_exec_cut_right\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_dir = path_misc +'output_subjects/'\n",
    "# for idx, file in tqdm(enumerate(os.listdir(output_dir))):\n",
    "#     if file.endswith('_seq.csv') and not file.endswith('_aligned_seq.csv'):\n",
    "#         file_path = os.path.join(output_dir, file)\n",
    "\n",
    "#         if os.path.exists(file_path.replace('_seq.csv', '_aligned_seq.csv')):\n",
    "#             continue\n",
    "\n",
    "#         subj_id = file.split('_')[1].replace('.csv', '')\n",
    "#         print(subj_id)\n",
    "\n",
    "#         if subj_id in discard_subjs:\n",
    "#             continue\n",
    "\n",
    "#         print(file_path)\n",
    "#         # Load the data from the CSV file\n",
    "#         subject_data_forces_exec = pd.read_csv(file_path)\n",
    "\n",
    "#         # baseline correction\n",
    "#         for bn, bndata in subject_data_forces_exec.groupby('BN'):\n",
    "#             for tn, tndata in bndata.groupby('TN'):\n",
    "#                 for force, data in tndata.groupby('Force_Number'):\n",
    "#                     baseline = data[data['time'] <= 15]['Force_Value'].mean()\n",
    "#                     subject_data_forces_exec.loc[data.index, 'Force_Value'] = data['Force_Value'] - baseline\n",
    "        \n",
    "#         subjs_force_exec_cut = utils.cut_force(subject_data_forces_exec, 0)\n",
    "#         subjs_force_exec_cut_left = utils.cut_force_left(subject_data_forces_exec)\n",
    "#         subjs_force_exec_cut_right = utils.cut_force_right(subject_data_forces_exec)\n",
    "\n",
    "#         del subject_data_forces_exec\n",
    "\n",
    "\n",
    "#         # aligning the forces\n",
    "#         n_samples = 300\n",
    "#         n_samples_left_right = 30\n",
    "#         aligned_cut_force = pd.DataFrame(columns=subjs_force_exec_cut.columns)\n",
    "#         interpolated_data = []\n",
    "#         x_center_interp = np.linspace(0, 1, n_samples)\n",
    "#         interval = x_center_interp[1] - x_center_interp[0]\n",
    "#         x_right_interp = np.linspace(x_center_interp[-1] + interval, x_center_interp[-1] + interval * n_samples_left_right, n_samples_left_right) - 1\n",
    "#         x_left_interp = np.linspace(x_center_interp[0] - interval * n_samples_left_right, x_center_interp[0] - interval, n_samples_left_right) + 1\n",
    "\n",
    "\n",
    "#         for sub, subdata in tqdm(subjs_force_exec_cut_left.groupby('SubNum')):\n",
    "#             for bn, bndata in subdata.groupby('BN'):\n",
    "#                 for tn, tndata in bndata.groupby('TN'):\n",
    "#                     for force, data in tndata.groupby('Force_Number'):\n",
    "#                         warped_force = np.interp(x_left_interp, np.linspace(0,1, len(data)), data['Force_Value'])\n",
    "\n",
    "                        \n",
    "#                         interpolated_df = pd.DataFrame({\n",
    "#                             'SubNum': sub,\n",
    "#                             'BN': bn,\n",
    "#                             'TN': tn,\n",
    "#                             'Force_Number': force,\n",
    "#                             'Force_Value': warped_force,\n",
    "#                             'time': x_left_interp  - 1,\n",
    "#                             'state': data['state'].iloc[0],\n",
    "#                             'timeReal': data['timeReal'].iloc[0],\n",
    "#                             'N': data['N'].iloc[0],\n",
    "#                             'seqNumb': data['seqNumb'].iloc[0],\n",
    "#                             'isError': data['isError'].iloc[0],\n",
    "#                             'points': data['points'].iloc[0]\n",
    "#                         })\n",
    "#                         # new_df = pd.concat([new_df, interpolated_df])\n",
    "#                         interpolated_data.append(interpolated_df)\n",
    "\n",
    "#         del subjs_force_exec_cut_left\n",
    "\n",
    "#         for sub, subdata in tqdm(subjs_force_exec_cut.groupby('SubNum')):\n",
    "#             for bn, bndata in subdata.groupby('BN'):\n",
    "#                 for tn, tndata in bndata.groupby('TN'):\n",
    "#                     for force, data in tndata.groupby('Force_Number'):\n",
    "#                         warped_force = np.interp(x_center_interp, np.linspace(0,1, len(data)), data['Force_Value'])\n",
    "\n",
    "                        \n",
    "#                         interpolated_df = pd.DataFrame({\n",
    "#                             'SubNum': sub,\n",
    "#                             'BN': bn,\n",
    "#                             'TN': tn,\n",
    "#                             'Force_Number': force,\n",
    "#                             'Force_Value': warped_force,\n",
    "#                             'time': x_center_interp,\n",
    "#                             'state': data['state'].iloc[0],\n",
    "#                             'timeReal': data['timeReal'].iloc[0],\n",
    "#                             'N': data['N'].iloc[0],\n",
    "#                             'seqNumb': data['seqNumb'].iloc[0],\n",
    "#                             'isError': data['isError'].iloc[0],\n",
    "#                             'points': data['points'].iloc[0]\n",
    "#                         })\n",
    "#                         # new_df = pd.concat([new_df, interpolated_df])\n",
    "#                         interpolated_data.append(interpolated_df)\n",
    "\n",
    "\n",
    "#         del subjs_force_exec_cut\n",
    "\n",
    "#         for sub, subdata in tqdm(subjs_force_exec_cut_right.groupby('SubNum')):\n",
    "#             for bn, bndata in subdata.groupby('BN'):\n",
    "#                 for tn, tndata in bndata.groupby('TN'):\n",
    "#                     for force, data in tndata.groupby('Force_Number'):\n",
    "#                         warped_force = np.interp(x_right_interp, np.linspace(0,1, len(data)), data['Force_Value'])\n",
    "                        \n",
    "#                         interpolated_df = pd.DataFrame({\n",
    "#                             'SubNum': sub,\n",
    "#                             'BN': bn,\n",
    "#                             'TN': tn,\n",
    "#                             'Force_Number': force,\n",
    "#                             'Force_Value': warped_force,\n",
    "#                             'time': x_right_interp  + 1,\n",
    "#                             'state': data['state'].iloc[0],\n",
    "#                             'timeReal': data['timeReal'].iloc[0],\n",
    "#                             'N': data['N'].iloc[0],\n",
    "#                             'seqNumb': data['seqNumb'].iloc[0],\n",
    "#                             'isError': data['isError'].iloc[0],\n",
    "#                             'points': data['points'].iloc[0]\n",
    "#                         })\n",
    "#                         # new_df = pd.concat([new_df, interpolated_df])\n",
    "#                         interpolated_data.append(interpolated_df)\n",
    "\n",
    "\n",
    "#         del subjs_force_exec_cut_right\n",
    "\n",
    "#         aligned_cut_force = pd.concat(interpolated_data, ignore_index=True)\n",
    "#         del interpolated_data\n",
    "#         aligned_cut_force.to_csv(file_path.replace('_seq.csv', '_aligned_seq.csv'), index=False)\n",
    "#         del aligned_cut_force\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import PCA\n",
    "# forces = [1,2,3,4,5]\n",
    "# import pickle\n",
    "\n",
    "# output_dir = path_misc +'output_subjects/'\n",
    "\n",
    "# # fig, axs = plt.subplots(38, 7, figsize = (40, 100))\n",
    "\n",
    "# num_sequences = 4\n",
    "# num_cores = mp.cpu_count()\n",
    "\n",
    "# reduced_forces_correct_dict = {}\n",
    "# reduced_forces_all_dict = {}\n",
    "# components = {}\n",
    "\n",
    "# n_dim_reduction = 30\n",
    "\n",
    "# subnum = 0\n",
    "# for idx, file in tqdm(enumerate(os.listdir(output_dir))):\n",
    "#     # if subnum != 0:\n",
    "#     #     continue\n",
    "\n",
    "#     if file.endswith('_aligned_seq.csv'):\n",
    "#         file_path = os.path.join(output_dir, file)\n",
    "#         print(file_path)\n",
    "#         aligned_cut_force = pd.read_csv(file_path)\n",
    "\n",
    "#         sub_id = file.split('_')[1]\n",
    "#         if sub_id in control_subjs:\n",
    "#             aligned_cut_force_optimization = aligned_cut_force[aligned_cut_force['BN'].isin(memory_topimization_blocks_control)]\n",
    "#         else:\n",
    "#             aligned_cut_force_optimization = aligned_cut_force[aligned_cut_force['BN'].isin(memory_optimization_blocks_treatment)]\n",
    "             \n",
    "\n",
    "#         for seqnum, seq_data in aligned_cut_force_optimization.groupby('seqNumb'):\n",
    "#             seq_data_correct = utils.remove_error_trials(seq_data)\n",
    "#             pivot_data = seq_data_correct.pivot_table(index = ['N'], columns = ['Force_Number', 'time'], values = 'Force_Value').dropna().to_numpy()\n",
    "#             pca = PCA()\n",
    "#             pca.fit(pivot_data)\n",
    "#             components[subnum, seqnum] = pca.components_[:n_dim_reduction]\n",
    "\n",
    "#             explained_variance = pca.explained_variance_ratio_\n",
    "#             dim_reduced = np.argmax(np.cumsum(explained_variance) >= 0.9)\n",
    "#             # print(dim_reduced)\n",
    "#             reduced_forces_correct_dict[subnum, seqnum] = pca.transform(pivot_data)[:,:n_dim_reduction]\n",
    "#             pivot_data = seq_data.pivot_table(index = ['N'], columns = ['Force_Number', 'time'], values = 'Force_Value').fillna(0).to_numpy()\n",
    "#             reduced_forces_all_dict[subnum, seqnum] = pca.transform(pivot_data)[:,:n_dim_reduction]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#             # ax_ind = (subnum, seqnum - 1)\n",
    "#             # axs[ax_ind].plot(np.arange(1, len(explained_variance) + 1), explained_variance, marker = 'o', linestyle = '--')\n",
    "#             # axs[ax_ind].set_title(f'Subject {subnum} Sequence {seqnum}')\n",
    "#             # axs[ax_ind].set_xlabel('Principal Component')\n",
    "#             # axs[ax_ind].set_ylabel('Explained Variance')\n",
    "\n",
    "#         subnum += 1\n",
    "        \n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save(path_misc + 'reduced_forces_correct_dict.npy', reduced_forces_correct_dict)\n",
    "# np.save(path_misc + 'reduced_forces_all_dict.npy', reduced_forces_all_dict)\n",
    "# np.save(path_misc + 'components.npy', components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_forces_all_dict = np.load(path_misc + 'reduced_forces_all_dict.npy', allow_pickle=True).item()\n",
    "reduced_forces_correct_dict = np.load(path_misc + 'reduced_forces_correct_dict.npy', allow_pickle=True).item()\n",
    "components = np.load(path_misc + 'components.npy', allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "forces = [1,2,3,4,5]\n",
    "import pickle\n",
    "\n",
    "output_dir = path_misc +'output_subjects/'\n",
    "\n",
    "\n",
    "num_cores = mp.cpu_count()\n",
    "\n",
    "subnum_to_subid = {}\n",
    "\n",
    "\n",
    "subnum = 0\n",
    "for idx, file in tqdm(enumerate(os.listdir(output_dir))):\n",
    "\n",
    "\n",
    "    if file.endswith('_aligned_seq.csv'):\n",
    "        file_path = os.path.join(output_dir, file)\n",
    "        # print(file_path)\n",
    "\n",
    "\n",
    "        sub_id = file.split('_')[1]\n",
    "        if sub_id in control_subjs:\n",
    "            group = 'control'\n",
    "        else:\n",
    "            group = sub_group[sub_id]\n",
    "\n",
    "        subnum_to_subid[subnum] = sub_id\n",
    "\n",
    "\n",
    "        subnum += 1\n",
    "        \n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "forces = [1,2,3,4,5]\n",
    "import pickle\n",
    "\n",
    "output_dir = path_misc +'output_subjects/'\n",
    "\n",
    "fig, axs = plt.subplots(38, 7, figsize = (40, 200))\n",
    "\n",
    "num_cores = mp.cpu_count()\n",
    "\n",
    "component_rank = 0\n",
    "cmap = cm.Pastel1\n",
    "subnum = 0\n",
    "for idx, file in tqdm(enumerate(os.listdir(output_dir))):\n",
    "    # if subnum != 0:\n",
    "    #     continue\n",
    "\n",
    "    if file.endswith('_aligned_seq.csv'):\n",
    "        file_path = os.path.join(output_dir, file)\n",
    "        # print(file_path)\n",
    "        aligned_cut_force = pd.read_csv(file_path)\n",
    "\n",
    "        sub_id = file.split('_')[1]\n",
    "        if sub_id in control_subjs:\n",
    "            aligned_cut_force_optimization = aligned_cut_force[aligned_cut_force['BN'].isin(memory_topimization_blocks_control)]\n",
    "            group = 'control'\n",
    "        else:\n",
    "            aligned_cut_force_optimization = aligned_cut_force[aligned_cut_force['BN'].isin(memory_optimization_blocks_treatment)]\n",
    "            group = sub_group[sub_id]\n",
    "\n",
    "        for seqnum, seq_data in aligned_cut_force_optimization.groupby('seqNumb'):\n",
    "            seq_data_correct = utils.remove_error_trials(seq_data)\n",
    "            pivot_data = seq_data_correct.pivot_table(index = ['N'], columns = ['Force_Number', 'time'], values = 'Force_Value').dropna().to_numpy()\n",
    "            mean_forces = np.mean(pivot_data, axis = 0).reshape(len(fingers), n_samples_left_right * 2 + n_samples)\n",
    "\n",
    "            forces = components[subnum, seqnum][component_rank].reshape(len(fingers), n_samples_left_right * 2 + n_samples)\n",
    "\n",
    "            ax_ind = (subnum, seqnum - 1)\n",
    "\n",
    "            for force_ind, force in enumerate(mean_forces):\n",
    "                axs[ax_ind].plot(force, linestyle = '--', color = cmap(force_ind))\n",
    "\n",
    "            for force_ind, force in enumerate(forces):\n",
    "                axs[ax_ind].plot(force * 10, label = f'force {force_ind + 1}', color = cmap(force_ind))\n",
    "            \n",
    "            axs[ax_ind].set_title(f'Subject {subnum} Sequence {seqnum} Group {group}')\n",
    "            axs[ax_ind].set_xlabel('Time')\n",
    "            axs[ax_ind].set_ylabel('Force')\n",
    "            axs[ax_ind].legend()\n",
    "\n",
    "        subnum += 1\n",
    "        \n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dissimilarity Analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(38, 7, figsize = (40, 200))\n",
    "for (subnum, seqnum), data in reduced_forces_correct_dict.items():\n",
    "    # if subnum != 0:\n",
    "    #     continue\n",
    "    distances = pd.DataFrame(index = range(data.shape[0]), columns = range(data.shape[0]), dtype = float)\n",
    "    for i in tqdm(range(data.shape[0]), desc = f'Processing Subject {subnum} Sequence {seqnum}'):\n",
    "        for j in range(data.shape[0]):\n",
    "            distances.loc[i, j] = np.linalg.norm(data[i] - data[j])\n",
    "\n",
    "    ax_ind = (subnum, seqnum - 1)\n",
    "    sub_id = subnum_to_subid[subnum]\n",
    "    if sub_id in control_subjs:\n",
    "        group = 'control'\n",
    "    else:\n",
    "        group = sub_group[sub_id]\n",
    "    sns.heatmap(distances, ax = axs[ax_ind], cmap = 'coolwarm')\n",
    "    axs[ax_ind].set_title(f'Subject {subnum} Sequence {seqnum} Group {group}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 798,
   "metadata": {},
   "outputs": [],
   "source": [
    "#zero out incorrect trials forces\n",
    "for (subnum, seqnum), data in reduced_forces_all_dict.items():\n",
    "    for i in range(data.shape[0]):\n",
    "        if i not in correct_trials[subnum, seqnum]:\n",
    "            data[i] = np.zeros(data.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distances_all = pd.DataFrame(columns = pd.MultiIndex.from_product([\n",
    "#     specific_sequences, ['G1', 'G2', 'control'], subjs_ids\n",
    "# ], names = ['Sequence', 'Group', 'Subject']), dtype = float)\n",
    "\n",
    "\n",
    "# for (subnum, seqnum), data in reduced_forces_all_dict.items():\n",
    "#     # if subnum > 10:\n",
    "#     #     continue\n",
    "#     distances = pd.DataFrame(index = range(data.shape[0]), columns = range(data.shape[0]), dtype = float)\n",
    "#     for i in tqdm(range(data.shape[0]), desc = f'Processing Subject {subnum} Sequence {seqnum}'):\n",
    "#         for j in range(data.shape[0]):\n",
    "#             distances.loc[i, j] = np.linalg.norm(data[i] - data[j])\n",
    "\n",
    "#     ax_ind = (subnum, seqnum - 1)\n",
    "#     sub_id = subnum_to_subid[subnum]\n",
    "#     if sub_id in control_subjs:\n",
    "#         group = 'control'\n",
    "#     else:\n",
    "#         group = sub_group[sub_id]\n",
    "\n",
    "#     flattened_distances = pd.Series(distances.to_numpy().flatten())\n",
    "#     distances_all[seqnum, group, sub_id] = flattened_distances\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 801,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances_all.to_csv(path_misc + 'distances_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances_all = pd.read_csv(path_misc + 'distances_all.csv', header = [0,1,2], index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 803,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrs = distances_all.corr()\n",
    "corrs = corrs.dropna(axis = 0, how = 'all').dropna(axis = 1, how = 'all')\n",
    "subjects = corrs.columns.get_level_values(2).unique()\n",
    "groups = corrs.columns.get_level_values(1).unique()\n",
    "sequences = corrs.columns.get_level_values(0).unique()\n",
    "\n",
    "# Define color palettes for each level\n",
    "subject_colors = sns.color_palette(\"Set3\", len(subjects))\n",
    "group_colors = sns.color_palette(\"Pastel1\", len(groups))\n",
    "sequence_colors = sns.color_palette(\"Dark2\", len(sequences))\n",
    "\n",
    "# Create color mappings\n",
    "subject_color_map = dict(zip(subjects, subject_colors))\n",
    "group_color_map = dict(zip(groups, group_colors))\n",
    "sequence_color_map = dict(zip(sequences, sequence_colors))\n",
    "\n",
    "# Map colors to each level of the multi-index\n",
    "sequence_colors_mapped = corrs.columns.get_level_values(0).map(sequence_color_map)\n",
    "group_colors_mapped = corrs.columns.get_level_values(1).map(group_color_map)\n",
    "subject_colors_mapped = corrs.columns.get_level_values(2).map(subject_color_map)\n",
    "\n",
    "\n",
    "# combined color mappings for each level to a multi-level df same as x\n",
    "col_colors = pd.DataFrame(\n",
    "    {\n",
    "        \"Sequence\": sequence_colors_mapped,\n",
    "        \"Group\": group_colors_mapped,\n",
    "        \"Subject\": subject_colors_mapped,\n",
    "    },\n",
    "    index=corrs.columns,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.clustermap(corrs, cmap = 'coolwarm', figsize = (40, 40), vmin = 0, vmax = 0.3, col_colors=col_colors, row_colors=col_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total variance of data in corrs matrix\n",
    "idx = pd.IndexSlice\n",
    "total_variance = np.var(corrs.to_numpy()[np.triu_indices_from(corrs.to_numpy())])\n",
    "print(total_variance)\n",
    "# print(corrs.to_numpy().mean())\n",
    "\n",
    "\n",
    "within_seq_values = []\n",
    "between_seq_values = []\n",
    "temp = np.array([])\n",
    "temp_corrs = corrs.copy()\n",
    "for seq in sequences.unique():\n",
    "    seq_corrs_across = temp_corrs.loc[idx[seq, :, :], idx[:, :, :]]\n",
    "    seq_corrs_within = temp_corrs.loc[idx[seq, :, :], idx[seq, :, :]]\n",
    "    # remove seq_corrs_within from seq_corrs_across\n",
    "    seq_corrs_across = seq_corrs_across.drop(labels = seq_corrs_within.columns, axis = 1)\n",
    "    seq_corrs_within = seq_corrs_within.to_numpy()\n",
    "\n",
    "    within_seq_values = np.append(within_seq_values, seq_corrs_within[np.triu_indices_from(seq_corrs_within)])\n",
    "    between_seq_values = np.append(between_seq_values, seq_corrs_across.to_numpy().flatten())\n",
    "\n",
    "    #drop seq from temp_corrs\n",
    "    temp_corrs = temp_corrs.drop(labels = seq, axis = 1, level = 0)\n",
    "\n",
    "\n",
    "seq_variance = np.var([within_seq_values.mean(), between_seq_values.mean()])\n",
    "\n",
    "    \n",
    "within_group_values = []\n",
    "between_group_values = []\n",
    "temp_corrs = corrs.copy()\n",
    "for group in groups.unique():\n",
    "    group_corss_across = temp_corrs.loc[idx[:, group, :], idx[:, :, :]]\n",
    "    group_corrs_within = temp_corrs.loc[idx[:, group, :], idx[:, group, :]]\n",
    "    group_corss_across = group_corss_across.drop(labels = group_corrs_within.columns, axis = 1)\n",
    "    group_corrs_within = group_corrs_within.to_numpy()\n",
    "\n",
    "    within_group_values = np.append(within_group_values, group_corrs_within[np.triu_indices_from(group_corrs_within)])\n",
    "    between_group_values = np.append(between_group_values, group_corss_across.to_numpy().flatten())\n",
    "\n",
    "\n",
    "    #drop group from temp_corrs\n",
    "    temp_corrs = temp_corrs.drop(labels = group, axis = 1, level = 1)\n",
    "\n",
    "\n",
    "group_variance = np.var([within_group_values.mean(), between_group_values.mean()])\n",
    "\n",
    "\n",
    "\n",
    "within_subj_values = []\n",
    "between_subj_values = []\n",
    "temp_corrs = corrs.copy()\n",
    "for subj in subjects.unique():\n",
    "    subj_corss_across = temp_corrs.loc[idx[:, :, subj], idx[:, :, :]]\n",
    "    subj_corrs_within = temp_corrs.loc[idx[:, :, subj], idx[:, :, subj]]\n",
    "    subj_corss_across = subj_corss_across.drop(labels = subj_corrs_within.columns, axis = 1)\n",
    "    subj_corrs_within = subj_corrs_within.to_numpy()\n",
    "\n",
    "    within_subj_values = np.append(within_subj_values, subj_corrs_within[np.triu_indices_from(subj_corrs_within)])\n",
    "    between_subj_values = np.append(between_subj_values, subj_corss_across.to_numpy().flatten())\n",
    "\n",
    "    #drop subj from temp_corrs\n",
    "    temp_corrs = temp_corrs.drop(labels = subj, axis = 1, level = 2)\n",
    "\n",
    "\n",
    "subj_variance = np.var([within_subj_values.mean(), between_subj_values.mean()])\n",
    "\n",
    "\n",
    "print(seq_variance, group_variance, subj_variance)\n",
    "print(f'seq: within {within_seq_values.mean()} between {between_seq_values.mean()}')\n",
    "print(f'group: within {within_group_values.mean()} between {between_group_values.mean()}')\n",
    "print(f'subj: within {within_subj_values.mean()} between {between_subj_values.mean()}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract upper triangle of the correlation matrix with their correspoding index and column names\n",
    "upper_triangle = corrs.to_numpy()[np.triu_indices_from(corrs)]\n",
    "upper_triangle_index = corrs.index.to_numpy()[np.triu_indices_from(corrs)[0]]\n",
    "upper_triangle_columns = corrs.columns.to_numpy()[np.triu_indices_from(corrs)[1]]\n",
    "\n",
    "rows = []\n",
    "for i in range(len(upper_triangle)):\n",
    "    index = upper_triangle_index[i]\n",
    "    column = upper_triangle_columns[i]\n",
    "    same_seq = index[0] == column[0]\n",
    "    same_group = index[1] == column[1]\n",
    "    same_subj = index[2] == column[2]\n",
    "    row = {\n",
    "        'same_seq': same_seq,\n",
    "        'same_group': same_group,\n",
    "        'same_subj': same_subj,\n",
    "        'corr': upper_triangle[i]\n",
    "    }\n",
    "    rows.append(row)\n",
    "data = pd.DataFrame(rows)\n",
    "\n",
    "# remove rows with same_seq, same_group, same_subj all true\n",
    "data = data[~(data['same_seq'] & data['same_group'] & data['same_subj'])]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.formula.api import ols\n",
    "import statsmodels.api as sm\n",
    "\n",
    "model = ols('corr ~ same_seq + same_group + same_subj', data = data).fit()\n",
    "\n",
    "print(sm.stats.anova_lm(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_corrs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_rel\n",
    "num_subjects = 38\n",
    "idx = pd.IndexSlice\n",
    "\n",
    "for seqnum in specific_sequences:\n",
    "    df = pd.DataFrame(columns = ['SubNum', 'within', 'between'])\n",
    "    seq_corrs = corrs.loc[idx[seqnum, :, :], idx[seqnum, :, :]]\n",
    "    for subid in corrs.columns.get_level_values(2).unique():\n",
    "        \n",
    "        if subid in control_subjs:\n",
    "            group = 'control'\n",
    "        else:\n",
    "            group = sub_group[subid]\n",
    "\n",
    "        within_group = seq_corrs.loc[idx[:, group, subid], idx[:, group, :]]\n",
    "        between_group = seq_corrs.loc[idx[:, group, subid], idx[:, :, :]]\n",
    "        between_group = between_group.drop(labels = within_group.columns, axis = 1)\n",
    "        within_group = within_group.drop(labels = within_group.index, axis = 1)\n",
    "\n",
    "        within_group = within_group.to_numpy().flatten()\n",
    "        between_group = between_group.to_numpy().flatten()\n",
    "        df.loc[len(df)] = [subid, within_group.mean(), between_group.mean()]\n",
    "\n",
    "    \n",
    "    if seqnum in seq_dict['G1']['aligned']:\n",
    "        seq_alignment = 'G1 aligned'\n",
    "    elif seqnum in seq_dict['G2']['aligned']:\n",
    "        seq_alignment = 'G2 aligned'\n",
    "    else:\n",
    "        seq_alignment = ''\n",
    "    \n",
    "    #t-test\n",
    "    print(f'Seq {seqnum} {seq_alignment}')\n",
    "    print(ttest_rel(df['within'], df['between'], alternative = 'two-sided'))\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_rel\n",
    "num_subjects = 38\n",
    "idx = pd.IndexSlice\n",
    "\n",
    "df = pd.DataFrame(columns = ['SubNum', 'within', 'between'])\n",
    "\n",
    "\n",
    "for subid in corrs.columns.get_level_values(2).unique():\n",
    "    \n",
    "    if subid in control_subjs:\n",
    "        group = 'control'\n",
    "    else:\n",
    "        group = sub_group[subid]\n",
    "        \n",
    "\n",
    "    within_group = corrs.loc[idx[:, group, subid], idx[:, group, :]]\n",
    "    between_group = corrs.loc[idx[:, group, subid], idx[:, :, :]]\n",
    "    between_group = between_group.drop(labels = within_group.columns, axis = 1)\n",
    "    within_group = within_group.drop(labels = within_group.index, axis = 1)\n",
    "\n",
    "    within_group = within_group.to_numpy().flatten()\n",
    "    between_group = between_group.to_numpy().flatten()\n",
    "    df.loc[len(df)] = [subid, within_group.mean(), between_group.mean()]\n",
    "\n",
    "\n",
    "\n",
    "#t-test\n",
    "print(ttest_rel(df['within'], df['between'], alternative = 'two-sided'))\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_rel\n",
    "num_subjects = 38\n",
    "idx = pd.IndexSlice\n",
    "\n",
    "df = pd.DataFrame(columns = ['SubNum', 'within', 'between'])\n",
    "\n",
    "\n",
    "for subid in corrs.columns.get_level_values(2).unique():\n",
    "    \n",
    "    if subid in control_subjs:\n",
    "        group = 'control'\n",
    "    else:\n",
    "        group = sub_group[subid]\n",
    "\n",
    "    within_seq_values = []\n",
    "    between_seq_values = []\n",
    "    for seqnum in specific_sequences:\n",
    "        within_group = corrs.loc[idx[seqnum, :, subid], idx[seqnum, :, :]]\n",
    "        between_group = corrs.loc[idx[seqnum, :, subid], idx[:, :, :]]\n",
    "        between_group = between_group.drop(labels = within_group.columns, axis = 1)\n",
    "        within_group = within_group.drop(labels = within_group.index, axis = 1)\n",
    "        within_seq_values = np.append(within_seq_values, within_group.to_numpy().flatten())\n",
    "        between_seq_values = np.append(between_seq_values, between_group.to_numpy().flatten())\n",
    "\n",
    "    df.loc[len(df)] = [subid, within_seq_values.mean(), between_seq_values.mean()]\n",
    "\n",
    "\n",
    "#t-test\n",
    "print(ttest_rel(df['within'], df['between'], alternative = 'greater'))\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "within_group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group Space Analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import PCA\n",
    "# forces = [1,2,3,4,5]\n",
    "# import pickle\n",
    "\n",
    "# output_dir = path_misc +'output_subjects/'\n",
    "\n",
    "# for seqnum in specific_sequences:\n",
    "#     seq_cut_force = []\n",
    "#     for idx, file in tqdm(enumerate(os.listdir(output_dir))):\n",
    "#         # if subnum != 0:\n",
    "#         #     continue\n",
    "\n",
    "#         if file.endswith('_aligned_seq.csv'):\n",
    "#             file_path = os.path.join(output_dir, file)\n",
    "#             # print(file_path)\n",
    "#             aligned_cut_force = pd.read_csv(file_path)\n",
    "#             aligned_cut_force = aligned_cut_force[aligned_cut_force['seqNumb'] == seqnum]\n",
    "\n",
    "#             sub_id = file.split('_')[1]\n",
    "#             if sub_id in control_subjs:\n",
    "#                 aligned_cut_force_optimization = aligned_cut_force[aligned_cut_force['BN'].isin(memory_topimization_blocks_control)]\n",
    "#                 group = 'control'\n",
    "#             else:\n",
    "#                 aligned_cut_force_optimization = aligned_cut_force[aligned_cut_force['BN'].isin(memory_optimization_blocks_treatment)]\n",
    "#                 group = sub_group[sub_id]\n",
    "            \n",
    "#             seq_cut_force.append(aligned_cut_force_optimization)\n",
    "#     seq_cut_force = pd.concat(seq_cut_force, axis = 0)\n",
    "#     seq_cut_force.to_csv(path_misc + f'seq_{seqnum}_aligned_memory_optimization.csv', index = False)\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "forces = [1,2,3,4,5]\n",
    "import pickle\n",
    "from matplotlib import cm \n",
    "\n",
    "output_dir = path_misc +'output_subjects/'\n",
    "\n",
    "reduced_forces_group_correct_dict = {}\n",
    "reduced_forces_group_all_dict = {}\n",
    "components_group = {}\n",
    "pca_group = {}\n",
    "n_dim_reduction = 40\n",
    "pivot_datas = defaultdict(list)\n",
    "\n",
    "cmap = cm.Pastel1\n",
    "subnum = 0\n",
    "\n",
    "for seqnum in specific_sequences:\n",
    "\n",
    "    seq_file = path_misc + f'seq_{seqnum}_aligned_memory_optimization.csv'\n",
    "    seq_data = pd.read_csv(seq_file)\n",
    "    seq_data_correct = utils.remove_error_trials(seq_data)\n",
    "\n",
    "    pivot_data = seq_data_correct.pivot_table(index = ['SubNum', 'N'], columns = ['Force_Number', 'time'], values = 'Force_Value').dropna().to_numpy()\n",
    "\n",
    "    pca = PCA()\n",
    "    pca.fit(pivot_data)\n",
    "    components_group[seqnum] = pca.components_[:n_dim_reduction]\n",
    "    pca_group[seqnum] = pca\n",
    "    explained_variance = pca.explained_variance_ratio_\n",
    "    dim_reduced = np.argmax(np.cumsum(explained_variance) >= 0.9)\n",
    "    # print(dim_reduced)\n",
    "\n",
    "\n",
    "for idx, file in tqdm(enumerate(os.listdir(output_dir))):\n",
    "    # if subnum != 0:\n",
    "    #     continue\n",
    "    if file.endswith('_aligned_seq.csv'):\n",
    "        file_path = os.path.join(output_dir, file)\n",
    "        aligned_cut_force = pd.read_csv(file_path)\n",
    "\n",
    "        sub_id = file.split('_')[1]\n",
    "        if sub_id in control_subjs:\n",
    "            aligned_cut_force_optimization = aligned_cut_force[aligned_cut_force['BN'].isin(memory_topimization_blocks_control)]\n",
    "            group = 'control'\n",
    "        else:\n",
    "            aligned_cut_force_optimization = aligned_cut_force[aligned_cut_force['BN'].isin(memory_optimization_blocks_treatment)]\n",
    "            group = sub_group[sub_id]\n",
    "        \n",
    "        for seqnum, seq_data in aligned_cut_force_optimization.groupby('seqNumb'):\n",
    "            seq_data_correct = utils.remove_error_trials(seq_data)\n",
    "            pivot_data = seq_data_correct.pivot_table(index = ['N'], columns = ['Force_Number', 'time'], values = 'Force_Value').dropna().to_numpy()\n",
    "            reduced_forces_group_correct_dict[subnum, seqnum] = pca_group[seqnum].transform(pivot_data)[:,:n_dim_reduction]\n",
    "            pivot_data = seq_data.pivot_table(index = ['N'], columns = ['Force_Number', 'time'], values = 'Force_Value').dropna().to_numpy()\n",
    "            reduced_forces_group_all_dict[subnum, seqnum] = pca_group[seqnum].transform(pivot_data)[:,:n_dim_reduction]\n",
    "\n",
    "\n",
    "        subnum += 1\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#project and plot random walk on the first 3 principal components interactively in 3D\n",
    "import plotly.graph_objects as go\n",
    "num_subjects = 38\n",
    "\n",
    "for seqnum in specific_sequences:\n",
    "    fig = go.Figure()\n",
    "    for subnum in range(num_subjects):\n",
    "        forces = reduced_forces_group_correct_dict[subnum, seqnum]\n",
    "        window_size = 51\n",
    "        kernel = np.ones(window_size) / window_size\n",
    "        smoothed_states = np.zeros_like(forces)\n",
    "        for i in range(n_dim_reduction):\n",
    "            smoothed_states[:,i] = np.convolve(forces[:,i], kernel, mode = 'same')\n",
    "        \n",
    "        color = np.arange(len(forces))\n",
    "\n",
    "        fig.add_trace(go.Scatter3d(x=smoothed_states[:,0], y=smoothed_states[:,1], z=smoothed_states[:,2], mode='lines', line=dict(color=color, colorscale='Viridis', width=1, showscale = True)))\n",
    "\n",
    "    fig.update_layout(scene = dict(\n",
    "                    xaxis_title='PC1',\n",
    "                    yaxis_title='PC2',\n",
    "                    zaxis_title='PC3'),\n",
    "                    width=800,\n",
    "                    height=800,\n",
    "                    margin=dict(l=100, r=100, b = 100, t=100),\n",
    "                    title_text = f'Seq {seqnum}')\n",
    "    fig.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#project and plot random walk on the first 3 principal components interactively in 3D\n",
    "import plotly.graph_objects as go\n",
    "num_subjects = 38\n",
    "cmap = cm.Pastel1\n",
    "\n",
    "for seqnum in specific_sequences:\n",
    "    fig = go.Figure()\n",
    "    for subnum in range(num_subjects):\n",
    "        sub_id = subnum_to_subid[subnum]\n",
    "        if sub_id in control_subjs:\n",
    "            group = 'control'\n",
    "        else:\n",
    "            group = sub_group[sub_id]\n",
    "        \n",
    "        forces = reduced_forces_group_correct_dict[subnum, seqnum]\n",
    "        window_size = 51\n",
    "        kernel = np.ones(window_size) / window_size\n",
    "        smoothed_states = np.zeros((forces.shape[0] - window_size + 1, n_dim_reduction))\n",
    "        for i in range(n_dim_reduction):\n",
    "            smoothed_states[:,i] = np.convolve(forces[:,i], kernel, mode = 'valid')\n",
    "\n",
    "\n",
    "        #determine color based on group \n",
    "        if group == 'control':\n",
    "            color = 'black'\n",
    "        else:\n",
    "            color = (lambda group: cmap(0) if group == 'G1' else cmap(1))(group)\n",
    "            color = (lambda group: 'red' if group == 'G1' else 'blue')(group)\n",
    "\n",
    "        \n",
    "        # plot start and end points in the first 3 principal components\n",
    "        fig.add_trace(go.Scatter3d(x=[smoothed_states[0,0]], y=[smoothed_states[0,1]], z=[smoothed_states[0,2]], mode='markers', name = f'{sub_id}({group})', legendgroup=sub_id,\n",
    "                                    marker=dict(size=10, color=color, opacity=0.3, symbol='circle')))\n",
    "        fig.add_trace(go.Scatter3d(x=[smoothed_states[-1,0]], y=[smoothed_states[-1,1]], z=[smoothed_states[-1,2]], mode='markers', showlegend=False, legendgroup=sub_id,\n",
    "                                   marker=dict(size=10, color=color, opacity=0.3, symbol = 'diamond')))\n",
    "        \n",
    "        # fig.add_trace(go.Scatter3d(x=smoothed_states[:,0], y=smoothed_states[:,1], z=smoothed_states[:,2], showlegend=False, mode='lines', line=dict(color=color, width=1)))\n",
    "\n",
    "\n",
    "    \n",
    "        \n",
    "        \n",
    "\n",
    "    fig.update_layout(scene = dict(\n",
    "                    xaxis_title='PC1',\n",
    "                    yaxis_title='PC2',\n",
    "                    zaxis_title='PC3'),\n",
    "                    width=800,\n",
    "                    height=800,\n",
    "                    margin=dict(l=100, r=100, b = 100, t=100),\n",
    "                    title_text = f'Seq {seqnum}', \n",
    "                    showlegend = True)\n",
    "    fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (subnum, seqnum), forces in reduced_forces_group_all_dict.items():\n",
    "    print(subnum, seqnum, forces.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#project and plot random walk on the first 3 principal components interactively in 3D\n",
    "import plotly.graph_objects as go\n",
    "num_subjects = 38\n",
    "cmap = cm.Pastel1\n",
    "\n",
    "for seqnum in specific_sequences:\n",
    "    fig = go.Figure()\n",
    "    starting_points = defaultdict(list)\n",
    "    ending_points = defaultdict(list)\n",
    "    for subnum in range(num_subjects):\n",
    "        sub_id = subnum_to_subid[subnum]\n",
    "        if sub_id in control_subjs:\n",
    "            group = 'control'\n",
    "        else:\n",
    "            group = sub_group[sub_id]\n",
    "        \n",
    "        forces = reduced_forces_group_correct_dict[subnum, seqnum]\n",
    "        window_size = 51\n",
    "        kernel = np.ones(window_size) / window_size\n",
    "        smoothed_states = np.zeros((forces.shape[0] - window_size + 1, n_dim_reduction))\n",
    "        for i in range(n_dim_reduction):\n",
    "            smoothed_states[:,i] = np.convolve(forces[:,i], kernel, mode = 'valid')\n",
    "\n",
    "        starting_points[group].append(smoothed_states[0])\n",
    "        ending_points[group].append(smoothed_states[-1])\n",
    "\n",
    "    for group in starting_points:\n",
    "        starts = np.array(starting_points[group])\n",
    "        ends = np.array(ending_points[group])\n",
    "        agg_start = np.mean(starts, axis = 0)\n",
    "        agg_end = np.mean(ends, axis = 0)\n",
    "\n",
    "        #between subjects standard error\n",
    "        agg_start_std = np.std(starts, axis = 0)\n",
    "        agg_end_std = np.std(ends, axis = 0)\n",
    "\n",
    "\n",
    "        #determine color based on group \n",
    "        if group == 'control':\n",
    "            color = 'black'\n",
    "        else:\n",
    "            color = (lambda group: cmap(0) if group == 'G1' else cmap(1))(group)\n",
    "            color = (lambda group: 'red' if group == 'G1' else 'blue')(group)\n",
    "\n",
    "\n",
    "        fig.add_trace(go.Scatter3d(x=[agg_start[0]], y=[agg_start[1]], z=[agg_start[2]], mode='markers', name = f'{group} start', legendgroup=group,\n",
    "                                    marker=dict(size=10, color=color, opacity=0.3, symbol='circle')))\n",
    "        fig.add_trace(go.Scatter3d(x=[agg_end[0]], y=[agg_end[1]], z=[agg_end[2]], mode='markers', name = f'{group} end', legendgroup=group,\n",
    "                                    marker=dict(size=10, color=color, opacity=0.3, symbol='diamond'))\n",
    "        )\n",
    "\n",
    "    if seqnum in seq_dict['G1']['aligned']:\n",
    "        title = f'Seq {seqnum} Group 1 Aligned'\n",
    "    elif seqnum in seq_dict['G2']['aligned']:\n",
    "        title = f'Seq {seqnum} Group 2 Aligned'\n",
    "    else:\n",
    "        title = f'Seq {seqnum}'\n",
    "    \n",
    "\n",
    "    fig.update_layout(scene = dict(\n",
    "                    xaxis_title='PC1',\n",
    "                    yaxis_title='PC2',\n",
    "                    zaxis_title='PC3'),\n",
    "                    width=800,\n",
    "                    height=800,\n",
    "                    margin=dict(l=100, r=100, b = 100, t=100),\n",
    "                    title_text = title, \n",
    "                    showlegend = True)\n",
    "\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from collections import defaultdict\n",
    "from matplotlib import cm\n",
    "\n",
    "def create_ellipsoid(center, radii, color, legendgroup, opacity=0.05):\n",
    "    u = np.linspace(0, 2 * np.pi, 100)\n",
    "    v = np.linspace(0, np.pi, 100)\n",
    "    x = radii[0] * np.outer(np.cos(u), np.sin(v)) + center[0]\n",
    "    y = radii[1] * np.outer(np.sin(u), np.sin(v)) + center[1]\n",
    "    z = radii[2] * np.outer(np.ones_like(u), np.cos(v)) + center[2]\n",
    "    return go.Surface(x=x, y=y, z=z, colorscale=[[0, color], [1, color]], opacity=opacity, showscale=False,\n",
    "                      legendgroup=legendgroup, showlegend=False)\n",
    "\n",
    "num_subjects = 38\n",
    "cmap = cm.Pastel1\n",
    "\n",
    "for seqnum in specific_sequences:\n",
    "    fig = go.Figure()\n",
    "    starting_points = defaultdict(list)\n",
    "    ending_points = defaultdict(list)\n",
    "\n",
    "    for subnum in range(num_subjects):\n",
    "        sub_id = subnum_to_subid[subnum]\n",
    "        if sub_id in control_subjs:\n",
    "            group = 'control'\n",
    "        else:\n",
    "            group = sub_group[sub_id]\n",
    "        \n",
    "        forces = reduced_forces_group_correct_dict[subnum, seqnum]\n",
    "        window_size = 51\n",
    "        kernel = np.ones(window_size) / window_size\n",
    "        smoothed_states = np.zeros((forces.shape[0] - window_size + 1, n_dim_reduction))\n",
    "        for i in range(n_dim_reduction):\n",
    "            smoothed_states[:, i] = np.convolve(forces[:, i], kernel, mode='valid')\n",
    "\n",
    "        starting_points[group].append(smoothed_states[0])\n",
    "        ending_points[group].append(smoothed_states[-1])\n",
    "\n",
    "    for group in starting_points:\n",
    "        starts = np.array(starting_points[group])\n",
    "        ends = np.array(ending_points[group])\n",
    "        agg_start = np.mean(starts, axis=0)\n",
    "        agg_end = np.mean(ends, axis=0)\n",
    "\n",
    "        # Between-subjects standard error\n",
    "        agg_start_std = np.std(starts, axis=0)\n",
    "        agg_end_std = np.std(ends, axis=0)\n",
    "\n",
    "        # Determine color based on group \n",
    "        if group == 'control':\n",
    "            color = 'black'\n",
    "        else:\n",
    "            color = 'red' if group == 'G1' else 'blue'\n",
    "\n",
    "        # Add ellipsoid for start\n",
    "        fig.add_trace(create_ellipsoid(center=agg_start, radii=agg_start_std, color=color, legendgroup=group))\n",
    "        # Add ellipsoid for end\n",
    "        fig.add_trace(create_ellipsoid(center=agg_end, radii=agg_end_std, color=color, legendgroup=group))\n",
    "\n",
    "        # Add start and end points\n",
    "        fig.add_trace(go.Scatter3d(\n",
    "            x=[agg_start[0]], y=[agg_start[1]], z=[agg_start[2]],\n",
    "            mode='markers', name=f'{group} start', legendgroup=group,\n",
    "            marker=dict(size=10, color=color, opacity=1.0, symbol='circle')))\n",
    "        fig.add_trace(go.Scatter3d(\n",
    "            x=[agg_end[0]], y=[agg_end[1]], z=[agg_end[2]],\n",
    "            mode='markers', name=f'{group} end', legendgroup=group,\n",
    "            marker=dict(size=10, color=color, opacity=1.0, symbol='diamond')))\n",
    "\n",
    "    if seqnum in seq_dict['G1']['aligned']:\n",
    "        title = f'Seq {seqnum} Group 1 Aligned'\n",
    "    elif seqnum in seq_dict['G2']['aligned']:\n",
    "        title = f'Seq {seqnum} Group 2 Aligned'\n",
    "    else:\n",
    "        title = f'Seq {seqnum}'\n",
    "\n",
    "    fig.update_layout(scene=dict(\n",
    "        xaxis_title='PC1',\n",
    "        yaxis_title='PC2',\n",
    "        zaxis_title='PC3'),\n",
    "        width=800,\n",
    "        height=800,\n",
    "        margin=dict(l=100, r=100, b=100, t=100),\n",
    "        title_text=title,\n",
    "        showlegend=True)\n",
    "\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#project and plot random walk on the first 3 principal components interactively in 3D\n",
    "import plotly.graph_objects as go\n",
    "from scipy.stats import ttest_1samp\n",
    "from scipy.stats import t\n",
    "\n",
    "num_subjects = 38\n",
    "cmap = cm.cividis\n",
    "\n",
    "for seqnum in specific_sequences:\n",
    "    fig = go.Figure()\n",
    "    starting_points = defaultdict(list)\n",
    "    ending_points = defaultdict(list)\n",
    "    for subnum in range(num_subjects):\n",
    "        sub_id = subnum_to_subid[subnum]\n",
    "        if sub_id in control_subjs:\n",
    "            group = 'control'\n",
    "        else:\n",
    "            group = sub_group[sub_id]\n",
    "        \n",
    "        forces = reduced_forces_group_correct_dict[subnum, seqnum]\n",
    "        window_size = 51\n",
    "        kernel = np.ones(window_size) / window_size\n",
    "        smoothed_states = np.zeros((forces.shape[0] - window_size + 1, n_dim_reduction))\n",
    "        for i in range(n_dim_reduction):\n",
    "            smoothed_states[:,i] = np.convolve(forces[:,i], kernel, mode = 'valid')\n",
    "\n",
    "        starting_points[group].append(smoothed_states[0])\n",
    "        ending_points[group].append(smoothed_states[-1])\n",
    "\n",
    "    fig = plt.figure()\n",
    "    print(f'Seq {seqnum}')\n",
    "    for group in starting_points:\n",
    "        starts = np.array(starting_points[group])\n",
    "        ends = np.array(ending_points[group])\n",
    "        agg_start = np.mean(starts, axis = 0)\n",
    "        agg_end = np.mean(ends, axis = 0)\n",
    "\n",
    "        end_start_diff = ends - starts\n",
    "        \n",
    "        #within group correlations between end_start_diff\n",
    "        corr = np.corrcoef(end_start_diff)\n",
    "        corrs = corr[np.triu_indices(corr.shape[0], k = 1)]\n",
    "\n",
    "        if group == 'control':\n",
    "            color = 'black'\n",
    "        else:\n",
    "            color = (lambda group: cmap(0) if group == 'G1' else cmap(200))(group)\n",
    "\n",
    "\n",
    "        # sns.histplot(corrs,  label = group, alpha = 0.5, stat = 'probability')\n",
    "        plt.hist(corrs, bins = 20, alpha = 0.3, label = group, density = True, color = color)\n",
    "        dof = end_start_diff.shape[0] - 2 \n",
    "        mean_corr = np.mean(corrs)\n",
    "        std_dev = np.std(corrs, ddof = 1)\n",
    "        t_stat = mean_corr / (std_dev / np.sqrt(len(corrs)))\n",
    "        p_val = t.sf(np.abs(t_stat), dof) * 2\n",
    "\n",
    "        print(f'{group} mean_corr: {mean_corr} pval: {p_val}')\n",
    "\n",
    "    if seqnum in seq_dict['G1']['aligned']:\n",
    "        title = f'Seq {seqnum} Group 1 Aligned'\n",
    "    elif seqnum in seq_dict['G2']['aligned']:\n",
    "        title = f'Seq {seqnum} Group 2 Aligned'\n",
    "    else:\n",
    "        title = f'Seq {seqnum}'\n",
    "\n",
    "    plt.title(title)\n",
    "\n",
    "    plt.legend()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#project and plot random walk on the first 3 principal components interactively in 3D\n",
    "import plotly.graph_objects as go\n",
    "from scipy.stats import ttest_1samp\n",
    "num_subjects = 38\n",
    "cmap = cm.cividis\n",
    "\n",
    "for seqnum in specific_sequences:\n",
    "    fig = go.Figure()\n",
    "    starting_points = defaultdict(list)\n",
    "    ending_points = defaultdict(list)\n",
    "    for subnum in range(num_subjects):\n",
    "        sub_id = subnum_to_subid[subnum]\n",
    "        if sub_id in control_subjs:\n",
    "            group = 'control'\n",
    "        else:\n",
    "            group = sub_group[sub_id]\n",
    "        \n",
    "        forces = reduced_forces_group_correct_dict[subnum, seqnum]\n",
    "        window_size = 51\n",
    "        kernel = np.ones(window_size) / window_size\n",
    "        smoothed_states = np.zeros((forces.shape[0] - window_size + 1, n_dim_reduction))\n",
    "        for i in range(n_dim_reduction):\n",
    "            smoothed_states[:,i] = np.convolve(forces[:,i], kernel, mode = 'valid')\n",
    "\n",
    "        starting_points[group].append(smoothed_states[0])\n",
    "        ending_points[group].append(smoothed_states[-1])\n",
    "\n",
    "    fig = plt.figure()\n",
    "    print(f'Seq {seqnum}')\n",
    "    end_start_diffs = {}\n",
    "    for group in starting_points:\n",
    "        starts = np.array(starting_points[group])\n",
    "        ends = np.array(ending_points[group])\n",
    "        agg_start = np.mean(starts, axis = 0)\n",
    "        agg_end = np.mean(ends, axis = 0)\n",
    "\n",
    "        end_start_diff = ends - starts\n",
    "        end_start_diffs[group] = end_start_diff\n",
    "\n",
    "\n",
    "    #between group correlations between end_start_diff\n",
    "    clr_idx = 0\n",
    "    for group1 in end_start_diffs:\n",
    "        for group2 in end_start_diffs:\n",
    "            if group1 == group2 or (group2 > group1):\n",
    "                continue\n",
    "            corrs = np.corrcoef(end_start_diffs[group1], end_start_diffs[group2])\n",
    "            # choose elements belonging to different groups\n",
    "            corrs = corrs[:len(end_start_diffs[group1]), len(end_start_diffs[group1]):]\n",
    "            corrs = corrs.flatten()\n",
    "\n",
    "            plt.hist(corrs, bins = 20, alpha = 0.2, label = f'{group1} vs {group2}', density = True, color = cmap(clr_idx))\n",
    "            clr_idx += 150\n",
    "            print(f'{group1} vs {group2} mean_corr: {corrs.mean()} pval: {ttest_1samp(corrs, 0)[1]}')\n",
    "    \n",
    "    if seqnum in seq_dict['G1']['aligned']:\n",
    "        title = f'Seq {seqnum} Group 1 Aligned'\n",
    "    elif seqnum in seq_dict['G2']['aligned']:\n",
    "        title = f'Seq {seqnum} Group 2 Aligned'\n",
    "    else:\n",
    "        title = f'Seq {seqnum}'\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#project and plot random walk on the first 3 principal components interactively in 3D\n",
    "import plotly.graph_objects as go\n",
    "from scipy.stats import ttest_1samp\n",
    "from statsmodels.multivariate.manova import MANOVA\n",
    "num_subjects = 38\n",
    "cmap = cm.cividis\n",
    "n_pcs_for_test = 3\n",
    "\n",
    "for seqnum in specific_sequences:\n",
    "    columns = ['SubNum', 'Group', 'StartEnd']\n",
    "    columns += [f'PC{i}' for i in range(1, n_pcs_for_test + 1)]\n",
    "    df = pd.DataFrame(columns=columns)\n",
    "\n",
    "\n",
    "    for subnum in range(num_subjects):\n",
    "        sub_id = subnum_to_subid[subnum]\n",
    "        if sub_id in control_subjs:\n",
    "            group = 'control'\n",
    "        else:\n",
    "            group = sub_group[sub_id]\n",
    "        \n",
    "        forces = reduced_forces_group_correct_dict[subnum, seqnum]\n",
    "        window_size = 51\n",
    "        kernel = np.ones(window_size) / window_size\n",
    "        smoothed_states = np.zeros((forces.shape[0] - window_size + 1, n_dim_reduction))\n",
    "        for i in range(n_dim_reduction):\n",
    "            smoothed_states[:,i] = np.convolve(forces[:,i], kernel, mode = 'valid')\n",
    "\n",
    "        # append start and end point to the dataframe\n",
    "        start_point = smoothed_states[0][:n_pcs_for_test]\n",
    "        end_point = smoothed_states[-1][:n_pcs_for_test]\n",
    "        \n",
    "        start_row = [sub_id, group, 'start'] + start_point.tolist()\n",
    "        end_row = [sub_id, group, 'end'] + end_point.tolist()\n",
    "        \n",
    "        df.loc[len(df)] = start_row\n",
    "        df.loc[len(df)] = end_row\n",
    "\n",
    "    #include only G1 and G2\n",
    "    df = df[df['Group'] != 'control']\n",
    "    \n",
    "    # MANOVA\n",
    "    dependent_vars = [f'PC{i}' for i in range(1, n_pcs_for_test + 1)]\n",
    "    formula = f\"{'+'.join(dependent_vars)} ~ Group + StartEnd + Group:StartEnd\"\n",
    "    manova = MANOVA.from_formula(formula, data=df)\n",
    "    # print(df)\n",
    "    print(f'Seq {seqnum}')\n",
    "    print(manova.mv_test())\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequence Specific Training Recipe Effect Analysis:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_rel\n",
    "\n",
    "for seqnum in specific_sequences:\n",
    "\n",
    "    columns = ['SubNum', 'Group', 'StartEnd', 'Force']\n",
    "    df = pd.DataFrame(columns=columns)\n",
    "\n",
    "    df_within_between = pd.DataFrame(columns=['SubNum', 'within', 'between', 'StartEnd'])\n",
    "\n",
    "    for subnum in range(num_subjects):\n",
    "        sub_id = subnum_to_subid[subnum]\n",
    "        if sub_id in control_subjs:\n",
    "            group = 'control'\n",
    "        else:\n",
    "            group = sub_group[sub_id]\n",
    "        forces = reduced_forces_group_correct_dict[subnum, seqnum]\n",
    "        window_size = 51\n",
    "        kernel = np.ones(window_size) / window_size\n",
    "        smoothed_states = np.zeros((forces.shape[0] - window_size + 1, n_dim_reduction))\n",
    "        for i in range(n_dim_reduction):\n",
    "            smoothed_states[:, i] = np.convolve(forces[:, i], kernel, mode='valid')\n",
    "\n",
    "        # append start and end point to the dataframe\n",
    "        start_point = smoothed_states[0]\n",
    "        end_point = smoothed_states[-1]\n",
    "\n",
    "        start_row = [sub_id, group, 'start', start_point]\n",
    "        end_row = [sub_id, group, 'end', end_point]\n",
    "\n",
    "        df.loc[len(df)] = start_row\n",
    "        df.loc[len(df)] = end_row\n",
    "\n",
    "    # include only G1 and G2\n",
    "    # df = df[df['Group'] != 'control']\n",
    "\n",
    "    #calculate within/between distances\n",
    "    for startend, start_data in df.groupby('StartEnd'):\n",
    "        for index, row in start_data.iterrows():\n",
    "            subject = row['SubNum']\n",
    "            group = row['Group']\n",
    "            force = row['Force']\n",
    "            within_group = start_data[(start_data['Group'] == group) & (start_data['SubNum'] != subject)]\n",
    "            between_group = start_data[start_data['Group'] != group]\n",
    "\n",
    "            within_group_forces = np.vstack(within_group['Force'])\n",
    "            between_group_forces = np.vstack(between_group['Force'])\n",
    "            within_group_distances = np.linalg.norm(within_group_forces - force, axis = 1)\n",
    "            between_group_distances = np.linalg.norm(between_group_forces - force, axis = 1)\n",
    "            \n",
    "            df_within_between.loc[len(df_within_between)] = [subject, within_group_distances.mean(), between_group_distances.mean(), startend]\n",
    "\n",
    "        \n",
    "    if seqnum in seq_dict['G1']['aligned']:\n",
    "        seq_alignment = 'G1 aligned'\n",
    "    elif seqnum in seq_dict['G2']['aligned']:\n",
    "        seq_alignment = 'G2 aligned'\n",
    "    else:\n",
    "        seq_alignment = ''\n",
    "\n",
    "    # t-test \n",
    "    print(f'Seq {seqnum} {seq_alignment}')\n",
    "    for startend, start_data in df_within_between.groupby('StartEnd'):\n",
    "        print(f' Group Difference {startend}')\n",
    "        print(ttest_rel(start_data['within'], start_data['between']))\n",
    "\n",
    "    print(f'between Group distance decreasing')\n",
    "    # print(df_within_between[df_within_between['StartEnd'] == 'start']['between'].mean())\n",
    "    # print(df_within_between[df_within_between['StartEnd'] == 'end']['between'].mean())\n",
    "    print(ttest_rel(df_within_between[df_within_between['StartEnd'] == 'start']['between'], df_within_between[df_within_between['StartEnd'] == 'end']['between'], alternative = 'greater'))\n",
    "\n",
    "    print(f'between Group distance increasing')\n",
    "    print(ttest_rel(df_within_between[df_within_between['StartEnd'] == 'start']['between'], df_within_between[df_within_between['StartEnd'] == 'end']['between'], alternative = 'less'))\n",
    "\n",
    "    print(f'within Group variance decreasing')\n",
    "    print(ttest_rel(df_within_between[df_within_between['StartEnd'] == 'start']['within'], df_within_between[df_within_between['StartEnd'] == 'end']['within'], alternative = 'greater'))\n",
    "    print(f'within Group variance increasing')\n",
    "    print(ttest_rel(df_within_between[df_within_between['StartEnd'] == 'start']['within'], df_within_between[df_within_between['StartEnd'] == 'end']['within'], alternative = 'less'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_rel\n",
    "\n",
    "df_within_between = pd.DataFrame(columns=['SubNum', 'within', 'between', 'StartEnd', 'SeqNum'])\n",
    "\n",
    "for seqnum in specific_sequences:\n",
    "\n",
    "    columns = ['SubNum', 'Group', 'StartEnd', 'Force']\n",
    "    df = pd.DataFrame(columns=columns)\n",
    "\n",
    "\n",
    "    for subnum in range(num_subjects):\n",
    "        sub_id = subnum_to_subid[subnum]\n",
    "        if sub_id in control_subjs:\n",
    "            group = 'control'\n",
    "        else:\n",
    "            group = sub_group[sub_id]\n",
    "        forces = reduced_forces_group_correct_dict[subnum, seqnum]\n",
    "        window_size = 51\n",
    "        kernel = np.ones(window_size) / window_size\n",
    "        smoothed_states = np.zeros((forces.shape[0] - window_size + 1, n_dim_reduction))\n",
    "        for i in range(n_dim_reduction):\n",
    "            smoothed_states[:, i] = np.convolve(forces[:, i], kernel, mode='valid')\n",
    "\n",
    "        # append start and end point to the dataframe\n",
    "        start_point = smoothed_states[0]\n",
    "        end_point = smoothed_states[-1]\n",
    "\n",
    "        start_row = [sub_id, group, 'start', start_point]\n",
    "        end_row = [sub_id, group, 'end', end_point]\n",
    "\n",
    "        df.loc[len(df)] = start_row\n",
    "        df.loc[len(df)] = end_row\n",
    "\n",
    "    # include only G1 and G2\n",
    "    # df = df[df['Group'] != 'control']\n",
    "\n",
    "    #calculate within/between distances\n",
    "    for startend, start_data in df.groupby('StartEnd'):\n",
    "        for index, row in start_data.iterrows():\n",
    "            subject = row['SubNum']\n",
    "            group = row['Group']\n",
    "            force = row['Force']\n",
    "            within_group = start_data[(start_data['Group'] == group) & (start_data['SubNum'] != subject)]\n",
    "            between_group = start_data[start_data['Group'] != group]\n",
    "\n",
    "            within_group_forces = np.vstack(within_group['Force'])\n",
    "            between_group_forces = np.vstack(between_group['Force'])\n",
    "            within_group_distances = np.linalg.norm(within_group_forces - force, axis = 1)\n",
    "            between_group_distances = np.linalg.norm(between_group_forces - force, axis = 1)\n",
    "            \n",
    "            df_within_between.loc[len(df_within_between)] = [subject, within_group_distances.mean(), between_group_distances.mean(), startend, seqnum]\n",
    "\n",
    "        \n",
    "\n",
    "df_within_between = df_within_between.groupby(['SubNum', 'StartEnd']).mean().reset_index()\n",
    "# t-test \n",
    "for startend, start_data in df_within_between.groupby('StartEnd'):\n",
    "    print(f' Group Difference {startend}')\n",
    "    print(ttest_rel(start_data['within'], start_data['between']))\n",
    "\n",
    "print(f'between Group distance decreasing')\n",
    "# print(df_within_between[df_within_between['StartEnd'] == 'start']['between'].mean())\n",
    "# print(df_within_between[df_within_between['StartEnd'] == 'end']['between'].mean())\n",
    "print(ttest_rel(df_within_between[df_within_between['StartEnd'] == 'start']['between'], df_within_between[df_within_between['StartEnd'] == 'end']['between'], alternative = 'greater'))\n",
    "\n",
    "print(f'between Group distance increasing')\n",
    "print(ttest_rel(df_within_between[df_within_between['StartEnd'] == 'start']['between'], df_within_between[df_within_between['StartEnd'] == 'end']['between'], alternative = 'less'))\n",
    "\n",
    "print(f'within Group variance decreasing')\n",
    "print(ttest_rel(df_within_between[df_within_between['StartEnd'] == 'start']['within'], df_within_between[df_within_between['StartEnd'] == 'end']['within'], alternative = 'greater'))\n",
    "print(f'within Group variance increasing')\n",
    "print(ttest_rel(df_within_between[df_within_between['StartEnd'] == 'start']['within'], df_within_between[df_within_between['StartEnd'] == 'end']['within'], alternative = 'less'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_rel\n",
    "\n",
    "for seqnum in specific_sequences:\n",
    "\n",
    "    columns = ['SubNum', 'Group', 'Direction Force']\n",
    "    df = pd.DataFrame(columns=columns)\n",
    "\n",
    "    df_within_between = pd.DataFrame(columns=['SubNum', 'within', 'between', 'Corr'])\n",
    "\n",
    "    for subnum in range(num_subjects):\n",
    "        sub_id = subnum_to_subid[subnum]\n",
    "        if sub_id in control_subjs:\n",
    "            group = 'control'\n",
    "        else:\n",
    "            group = sub_group[sub_id]\n",
    "        forces = reduced_forces_group_correct_dict[subnum, seqnum]\n",
    "        window_size = 51\n",
    "        kernel = np.ones(window_size) / window_size\n",
    "        smoothed_states = np.zeros((forces.shape[0] - window_size + 1, n_dim_reduction))\n",
    "        for i in range(n_dim_reduction):\n",
    "            smoothed_states[:, i] = np.convolve(forces[:, i], kernel, mode='valid')\n",
    "\n",
    "        # append start and end point to the dataframe\n",
    "        start_point = smoothed_states[0]\n",
    "        end_point = smoothed_states[-1]\n",
    "        direction = (end_point - start_point) / np.linalg.norm(end_point - start_point)\n",
    "        df.loc[len(df)] = [sub_id, group, direction]\n",
    "\n",
    "    # include only G1 and G2\n",
    "    # df = df[df['Group'] != 'control']\n",
    "\n",
    "    #calculate within/between correlations\n",
    "    for idx, row in df.iterrows():\n",
    "        subject = row['SubNum']\n",
    "        group = row['Group']\n",
    "        direction = row['Direction Force']\n",
    "        within_group = df[(df['Group'] == group) & (df['SubNum'] != subject)]\n",
    "        between_group = df[df['Group'] != group]\n",
    "\n",
    "        within_group_directions = np.vstack(within_group['Direction Force'])\n",
    "        between_group_directions = np.vstack(between_group['Direction Force'])\n",
    "        within_group_corrs = np.dot(within_group_directions, direction)\n",
    "        between_group_corrs = np.dot(between_group_directions, direction)\n",
    "        \n",
    "        df_within_between.loc[len(df_within_between)] = [subject, within_group_corrs.mean(), between_group_corrs.mean(), 'Corr']\n",
    "\n",
    "\n",
    "        \n",
    "    if seqnum in seq_dict['G1']['aligned']:\n",
    "        seq_alignment = 'G1 aligned'\n",
    "    elif seqnum in seq_dict['G2']['aligned']:\n",
    "        seq_alignment = 'G2 aligned'\n",
    "    else:\n",
    "        seq_alignment = ''\n",
    "\n",
    "    # t-test\n",
    "    print(f'Seq {seqnum} {seq_alignment}')\n",
    "    print('within group directions')\n",
    "    print(ttest_1samp(df_within_between['within'], 0))\n",
    "    print('between group directions')\n",
    "    print(ttest_1samp(df_within_between['between'], 0))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_rel\n",
    "\n",
    "df_within_between = pd.DataFrame(columns=['SubNum', 'within', 'between', 'Corr', 'SeqNum'])\n",
    "\n",
    "for seqnum in specific_sequences:\n",
    "\n",
    "    columns = ['SubNum', 'Group', 'Direction Force']\n",
    "    df = pd.DataFrame(columns=columns)\n",
    "\n",
    "    for subnum in range(num_subjects):\n",
    "        sub_id = subnum_to_subid[subnum]\n",
    "        if sub_id in control_subjs:\n",
    "            group = 'control'\n",
    "        else:\n",
    "            group = sub_group[sub_id]\n",
    "        forces = reduced_forces_group_correct_dict[subnum, seqnum]\n",
    "        window_size = 51\n",
    "        kernel = np.ones(window_size) / window_size\n",
    "        smoothed_states = np.zeros((forces.shape[0] - window_size + 1, n_dim_reduction))\n",
    "        for i in range(n_dim_reduction):\n",
    "            smoothed_states[:, i] = np.convolve(forces[:, i], kernel, mode='valid')\n",
    "\n",
    "        # append start and end point to the dataframe\n",
    "        start_point = smoothed_states[0]\n",
    "        end_point = smoothed_states[-1]\n",
    "        direction = (end_point - start_point) / np.linalg.norm(end_point - start_point)\n",
    "        df.loc[len(df)] = [sub_id, group, direction]\n",
    "\n",
    "    # include only G1 and G2\n",
    "    # df = df[df['Group'] != 'control']\n",
    "\n",
    "    #calculate within/between correlations\n",
    "    for idx, row in df.iterrows():\n",
    "        subject = row['SubNum']\n",
    "        group = row['Group']\n",
    "        direction = row['Direction Force']\n",
    "        within_group = df[(df['Group'] == group) & (df['SubNum'] != subject)]\n",
    "        between_group = df[df['Group'] != group]\n",
    "\n",
    "        within_group_directions = np.vstack(within_group['Direction Force'])\n",
    "        between_group_directions = np.vstack(between_group['Direction Force'])\n",
    "        within_group_corrs = np.dot(within_group_directions, direction)\n",
    "        between_group_corrs = np.dot(between_group_directions, direction)\n",
    "        \n",
    "        df_within_between.loc[len(df_within_between)] = [subject, within_group_corrs.mean(), between_group_corrs.mean(), 'Corr', seqnum]\n",
    "\n",
    "\n",
    "        \n",
    "df_within_between = df_within_between.groupby(['SubNum', 'Corr']).mean().reset_index()\n",
    "\n",
    "# t-test\n",
    "print('within group directions')\n",
    "print(ttest_1samp(df_within_between['within'], 0))\n",
    "print('between group directions')\n",
    "print(ttest_1samp(df_within_between['between'], 0))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repetition Analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "forces = [1,2,3,4,5]\n",
    "import pickle\n",
    "\n",
    "output_dir = path_misc +'output_subjects/'\n",
    "\n",
    "# fig, axs = plt.subplots(38, 7, figsize = (40, 100))\n",
    "correct_trials_rep = {}\n",
    "correct_trials = {}\n",
    "\n",
    "\n",
    "\n",
    "subnum = 0\n",
    "for idx, file in tqdm(enumerate(os.listdir(output_dir))):\n",
    "    # if subnum != 0:\n",
    "    #     continue\n",
    "\n",
    "    if file.endswith('_aligned_seq.csv'):\n",
    "        file_path = os.path.join(output_dir, file)\n",
    "        print(file_path)\n",
    "        # print('subnum', subnum)\n",
    "        aligned_cut_force = pd.read_csv(file_path)\n",
    "\n",
    "        sub_id = file.split('_')[1]\n",
    "        if sub_id in control_subjs:\n",
    "            aligned_cut_force_optimization = aligned_cut_force[aligned_cut_force['BN'].isin(memory_topimization_blocks_control)]\n",
    "        else:\n",
    "            aligned_cut_force_optimization = aligned_cut_force[aligned_cut_force['BN'].isin(memory_optimization_blocks_treatment)]\n",
    "             \n",
    "\n",
    "        for seqnum, seq_data in aligned_cut_force_optimization.groupby('seqNumb'):\n",
    "            seq_data_correct = utils.remove_error_trials(seq_data)\n",
    "            \n",
    "            pivot_data = seq_data_correct.pivot_table(index= ['BN', 'TN'], columns = ['Force_Number', 'time'],  values = 'Force_Value').dropna()\n",
    "\n",
    "            if sub_id in control_subjs:\n",
    "                subj_data = subjs_seq_control_optimization[(subjs_seq_control_optimization['SubNum'] == sub_id) & \n",
    "                                                        (subjs_seq_control_optimization['seqNumb'] == seqnum) & \n",
    "                                                        (subjs_seq_control_optimization['BN'].isin(memory_topimization_blocks_control))].reset_index()\n",
    "                subj_data_correct = utils.remove_error_trials(subj_data)\n",
    "            else:\n",
    "                subj_data = subjs_seq_treatment_optimization[(subjs_seq_treatment_optimization['SubNum'] == sub_id) & \n",
    "                                                        (subjs_seq_treatment_optimization['seqNumb'] == seqnum) & \n",
    "                                                        (subjs_seq_treatment_optimization['BN'].isin(memory_optimization_blocks_treatment))].reset_index()\n",
    "                subj_data_correct = utils.remove_error_trials(subj_data)\n",
    "\n",
    "            correct_trials[subnum, seqnum] = subj_data_correct.index.values\n",
    "\n",
    "            subj_data_filtered = subj_data_correct[subj_data_correct[['BN', 'TN']].apply(tuple, axis=1).isin(pivot_data.index)]\n",
    "            trials_rep = subj_data_filtered['rep'].to_numpy()\n",
    "            correct_trials_rep[subnum, seqnum] = trials_rep\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "                \n",
    "\n",
    "\n",
    "        subnum += 1\n",
    "        \n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct_trials_rep = {}\n",
    "\n",
    "# for (subnum, seqnum), _ in reduced_forces_group_correct_dict.items():\n",
    "#     sub_id = subnum_to_subid[subnum]\n",
    "#     if sub_id in control_subjs:\n",
    "#         subj_data = subjs_seq_control_optimization[(subjs_seq_control_optimization['SubNum'] == sub_id) & \n",
    "#                                                    (subjs_seq_control_optimization['seqNumb'] == seqnum) & \n",
    "#                                                    (subjs_seq_control_optimization['BN'].isin(memory_topimization_blocks_control))]\n",
    "#         subj_data = utils.remove_error_trials(subj_data)\n",
    "\n",
    "#     else:\n",
    "#         subj_data = subjs_seq_treatment_optimization[(subjs_seq_treatment_optimization['SubNum'] == sub_id) & \n",
    "#                                                    (subjs_seq_treatment_optimization['seqNumb'] == seqnum) & \n",
    "#                                                    (subjs_seq_treatment_optimization['BN'].isin(memory_optimization_blocks_treatment))]\n",
    "#         subj_data = utils.remove_error_trials(subj_data)\n",
    "        \n",
    "#     trials_rep = subj_data['rep'].to_numpy()\n",
    "#     correct_trials_rep[subnum, seqnum] = trials_rep\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 793,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (subnum, seqnum), trials_rep in correct_trials_rep.items():\n",
    "    if (len(trials_rep) != len(reduced_forces_group_correct_dict[subnum, seqnum])):\n",
    "        print(subnum, seqnum, len(trials_rep), len(reduced_forces_group_correct_dict[subnum, seqnum]), len(reduced_forces_correct_dict[subnum, seqnum]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "num_subjects = 38\n",
    "cmap = cm.Pastel1\n",
    "\n",
    "def create_ellipsoid(center, radii, color, legendgroup, opacity=0.05):\n",
    "    u = np.linspace(0, 2 * np.pi, 100)\n",
    "    v = np.linspace(0, np.pi, 100)\n",
    "    x = radii[0] * np.outer(np.cos(u), np.sin(v)) + center[0]\n",
    "    y = radii[1] * np.outer(np.sin(u), np.sin(v)) + center[1]\n",
    "    z = radii[2] * np.outer(np.ones_like(u), np.cos(v)) + center[2]\n",
    "    return go.Surface(x=x, y=y, z=z, colorscale=[[0, color], [1, color]], opacity=opacity, showscale=False,\n",
    "                      legendgroup=legendgroup, showlegend=False)\n",
    "\n",
    "for seqnum in specific_sequences:\n",
    "    fig = go.Figure()\n",
    "    avg_points_first_rep = defaultdict(list)\n",
    "    avg_points_second_rep = defaultdict(list)\n",
    "\n",
    "    for subnum in range(num_subjects):\n",
    "        sub_id = subnum_to_subid[subnum]\n",
    "        if sub_id in control_subjs:\n",
    "            group = 'control'\n",
    "        else:\n",
    "            group = sub_group[sub_id]\n",
    "        forces = reduced_forces_group_correct_dict[subnum, seqnum]\n",
    "        forces_rep1 = forces[correct_trials_rep[subnum, seqnum] == False]\n",
    "        forces_rep2 = forces[correct_trials_rep[subnum, seqnum] == True]\n",
    "        avg_points_first_rep[group].append(np.mean(forces_rep1, axis = 0))\n",
    "        avg_points_second_rep[group].append(np.mean(forces_rep2, axis = 0))\n",
    "\n",
    "    \n",
    "    for group in avg_points_first_rep:\n",
    "        agg_avg_first_rep = np.mean(avg_points_first_rep[group], axis = 0)\n",
    "        agg_avg_second_rep = np.mean(avg_points_second_rep[group], axis = 0)\n",
    "\n",
    "        agg_std_first_rep = np.std(avg_points_first_rep[group], axis = 0)\n",
    "        agg_std_second_rep = np.std(avg_points_second_rep[group], axis = 0)\n",
    "\n",
    "\n",
    "        if group == 'control':\n",
    "            color = 'black'\n",
    "        else:\n",
    "            color = (lambda group: cmap(0) if group == 'G1' else cmap(200))(group)\n",
    "            color = (lambda group: 'red' if group == 'G1' else 'blue')(group)\n",
    "        \n",
    "        \n",
    "        fig.add_trace(go.Scatter3d(x=[agg_avg_first_rep[0]], y=[agg_avg_first_rep[1]], z=[agg_avg_first_rep[2]], mode='markers', name = f'{group} first rep', legendgroup=group,\n",
    "                                    marker=dict(size=10, color=color, opacity=0.3, symbol='circle')))\n",
    "        fig.add_trace(go.Scatter3d(x=[agg_avg_second_rep[0]], y=[agg_avg_second_rep[1]], z=[agg_avg_second_rep[2]], mode='markers', name = f'{group} second rep', legendgroup=group,\n",
    "                                    marker=dict(size=10, color=color, opacity=0.3, symbol='diamond')))\n",
    "\n",
    "        # fig.add_trace(create_ellipsoid(center = agg_avg_first_rep[:3], radii = agg_std_first_rep[:3], color = color, legendgroup = group))\n",
    "        # fig.add_trace(create_ellipsoid(center = agg_avg_second_rep[:3], radii = agg_std_second_rep[:3], color = color, legendgroup = group))\n",
    "        # fig.add_trace(create_ellipsoid(center = agg_avg, radii = agg_std, color = color, legendgroup = group))\n",
    "\n",
    "    if seqnum in seq_dict['G1']['aligned']:\n",
    "        title = f'Seq {seqnum} Group 1 Aligned'\n",
    "    elif seqnum in seq_dict['G2']['aligned']:\n",
    "        title = f'Seq {seqnum} Group 2 Aligned'\n",
    "    else:\n",
    "        title = f'Seq {seqnum}'\n",
    "\n",
    "    fig.update_layout(scene = dict(\n",
    "                    xaxis_title='PC1',\n",
    "                    yaxis_title='PC2',\n",
    "                    zaxis_title='PC3'),\n",
    "                    width=800,\n",
    "                    height=800,\n",
    "                    margin=dict(l=100, r=100, b = 100, t=100),\n",
    "                    title_text = title, \n",
    "                    showlegend = True)\n",
    "    fig.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "forces = [1,2,3,4,5]\n",
    "import pickle\n",
    "from matplotlib import cm \n",
    "\n",
    "output_dir = path_misc +'output_subjects/'\n",
    "\n",
    "reduced_forces_global_correct_dict = {}\n",
    "reduced_forces_global_all_dict = {}\n",
    "\n",
    "n_dim_reduction = 55\n",
    "pivot_datas = []\n",
    "\n",
    "cmap = cm.Pastel1\n",
    "subnum = 0\n",
    "\n",
    "for seqnum in specific_sequences:\n",
    "\n",
    "    seq_file = path_misc + f'seq_{seqnum}_aligned_memory_optimization.csv'\n",
    "    seq_data = pd.read_csv(seq_file)\n",
    "    seq_data_correct = utils.remove_error_trials(seq_data)\n",
    "\n",
    "    pivot_data = seq_data_correct.pivot_table(index = ['seqNumb','SubNum', 'N'], columns = ['Force_Number', 'time'], values = 'Force_Value').dropna().to_numpy()\n",
    "    pivot_datas.append(pivot_data)\n",
    "\n",
    "    # pca = PCA()\n",
    "    # pca.fit(pivot_data)\n",
    "    # components_global[seqnum] = pca.components_[:n_dim_reduction]\n",
    "    # pca_global[seqnum] = pca\n",
    "    # explained_variance = pca.explained_variance_ratio_\n",
    "    # dim_reduced = np.argmax(np.cumsum(explained_variance) >= 0.9)\n",
    "    # print(dim_reduced)\n",
    "\n",
    "pca = PCA()\n",
    "pca.fit(np.concatenate(pivot_datas, axis = 0))\n",
    "components_global = pca.components_[:n_dim_reduction]\n",
    "pca_global = pca\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "dim_reduced = np.argmax(np.cumsum(explained_variance) >= 0.9)\n",
    "print(dim_reduced)\n",
    "\n",
    "\n",
    "for idx, file in tqdm(enumerate(os.listdir(output_dir))):\n",
    "    # if subnum != 0:\n",
    "    #     continue\n",
    "    if file.endswith('_aligned_seq.csv'):\n",
    "        file_path = os.path.join(output_dir, file)\n",
    "        aligned_cut_force = pd.read_csv(file_path)\n",
    "\n",
    "        sub_id = file.split('_')[1]\n",
    "        if sub_id in control_subjs:\n",
    "            aligned_cut_force_optimization = aligned_cut_force[aligned_cut_force['BN'].isin(memory_topimization_blocks_control)]\n",
    "            group = 'control'\n",
    "        else:\n",
    "            aligned_cut_force_optimization = aligned_cut_force[aligned_cut_force['BN'].isin(memory_optimization_blocks_treatment)]\n",
    "            group = sub_group[sub_id]\n",
    "        \n",
    "        for seqnum, seq_data in aligned_cut_force_optimization.groupby('seqNumb'):\n",
    "            seq_data_correct = utils.remove_error_trials(seq_data)\n",
    "            pivot_data = seq_data_correct.pivot_table(index = ['N'], columns = ['Force_Number', 'time'], values = 'Force_Value').dropna().to_numpy()\n",
    "            reduced_forces_global_correct_dict[subnum, seqnum] = pca_global.transform(pivot_data)[:,:n_dim_reduction]\n",
    "            pivot_data = seq_data.pivot_table(index = ['N'], columns = ['Force_Number', 'time'], values = 'Force_Value').dropna().to_numpy()\n",
    "            reduced_forces_global_all_dict[subnum, seqnum] = pca_global.transform(pivot_data)[:,:n_dim_reduction]\n",
    "\n",
    "\n",
    "        subnum += 1\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save(path_misc + 'reduced_forces_global_correct_dict.npy', reduced_forces_global_correct_dict)\n",
    "# np.save(path_misc + 'reduced_forces_global_all_dict.npy', reduced_forces_global_all_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 768,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_forces_global_all_dict = np.load(path_misc + 'reduced_forces_global_all_dict.npy', allow_pickle = True).item()\n",
    "reduced_forces_global_correct_dict = np.load(path_misc + 'reduced_forces_global_correct_dict.npy', allow_pickle = True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 769,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (subnum, seqnum), trials_rep in correct_trials_rep.items():\n",
    "    if (len(trials_rep) != len(reduced_forces_group_correct_dict[subnum, seqnum])):\n",
    "        print(subnum, seqnum, len(trials_rep), len(reduced_forces_group_correct_dict[subnum, seqnum]), len(reduced_forces_correct_dict[subnum, seqnum]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "num_subjects = 38\n",
    "cmap = cm.Pastel1\n",
    "\n",
    "def create_ellipsoid(center, radii, color, legendgroup, opacity=0.05):\n",
    "    u = np.linspace(0, 2 * np.pi, 100)\n",
    "    v = np.linspace(0, np.pi, 100)\n",
    "    x = radii[0] * np.outer(np.cos(u), np.sin(v)) + center[0]\n",
    "    y = radii[1] * np.outer(np.sin(u), np.sin(v)) + center[1]\n",
    "    z = radii[2] * np.outer(np.ones_like(u), np.cos(v)) + center[2]\n",
    "    return go.Surface(x=x, y=y, z=z, colorscale=[[0, color], [1, color]], opacity=opacity, showscale=False,\n",
    "                      legendgroup=legendgroup, showlegend=False)\n",
    "\n",
    "\n",
    "avg_points_first_rep = defaultdict(list)\n",
    "avg_points_second_rep = defaultdict(list)\n",
    "\n",
    "for seqnum in specific_sequences:\n",
    "    fig = go.Figure()\n",
    "    avg_points_first_rep = defaultdict(list)\n",
    "    avg_points_second_rep = defaultdict(list)\n",
    "\n",
    "    for subnum in range(num_subjects):\n",
    "        sub_id = subnum_to_subid[subnum]\n",
    "        if sub_id in control_subjs:\n",
    "            group = 'control'\n",
    "        else:\n",
    "            group = sub_group[sub_id]\n",
    "        forces = reduced_forces_group_correct_dict[subnum, seqnum]\n",
    "        forces_rep1 = forces[correct_trials_rep[subnum, seqnum] == False]\n",
    "        forces_rep2 = forces[correct_trials_rep[subnum, seqnum] == True]\n",
    "        avg_points_first_rep[group].append(np.mean(forces_rep1, axis = 0))\n",
    "        avg_points_second_rep[group].append(np.mean(forces_rep2, axis = 0))\n",
    "\n",
    "    \n",
    "    for group in avg_points_first_rep:\n",
    "        agg_avg_first_rep = np.mean(avg_points_first_rep[group], axis = 0)\n",
    "        agg_avg_second_rep = np.mean(avg_points_second_rep[group], axis = 0)\n",
    "        if group == 'control':\n",
    "            color = 'black'\n",
    "        else:\n",
    "            color = (lambda group: cmap(0) if group == 'G1' else cmap(200))(group)\n",
    "            color = (lambda group: 'red' if group == 'G1' else 'blue')(group)\n",
    "        \n",
    "        \n",
    "        fig.add_trace(go.Scatter3d(x=[agg_avg_first_rep[0]], y=[agg_avg_first_rep[1]], z=[agg_avg_first_rep[2]], mode='markers', name = f'{group} first rep', legendgroup=group,\n",
    "                                    marker=dict(size=10, color=color, opacity=0.3, symbol='circle')))\n",
    "        fig.add_trace(go.Scatter3d(x=[agg_avg_second_rep[0]], y=[agg_avg_second_rep[1]], z=[agg_avg_second_rep[2]], mode='markers', name = f'{group} second rep', legendgroup=group,\n",
    "                                    marker=dict(size=10, color=color, opacity=0.3, symbol='diamond')))\n",
    "        # fig.add_trace(create_ellipsoid(center = agg_avg, radii = agg_std, color = color, legendgroup = group))\n",
    "\n",
    "    if seqnum in seq_dict['G1']['aligned']:\n",
    "        title = f'Seq {seqnum} Group 1 Aligned'\n",
    "    elif seqnum in seq_dict['G2']['aligned']:\n",
    "        title = f'Seq {seqnum} Group 2 Aligned'\n",
    "    else:\n",
    "        title = f'Seq {seqnum}'\n",
    "\n",
    "    fig.update_layout(scene = dict(\n",
    "                    xaxis_title='PC1',\n",
    "                    yaxis_title='PC2',\n",
    "                    zaxis_title='PC3'),\n",
    "                    width=800,\n",
    "                    height=800,\n",
    "                    margin=dict(l=100, r=100, b = 100, t=100),\n",
    "                    title_text = title, \n",
    "                    showlegend = True)\n",
    "    fig.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "metadata": {},
   "outputs": [],
   "source": [
    "#project and plot random walk on the first 3 principal components interactively in 3D\n",
    "import plotly.graph_objects as go\n",
    "from scipy.stats import ttest_1samp\n",
    "from statsmodels.multivariate.manova import MANOVA\n",
    "\n",
    "num_subjects = 38\n",
    "cmap = cm.cividis\n",
    "n_pcs_for_test = 3\n",
    "\n",
    "columns = ['SubNum', 'Group', 'seqNumb', 'rep']\n",
    "columns += [f'PC{i}' for i in range(1, n_pcs_for_test + 1)]\n",
    "df = pd.DataFrame(columns=columns)\n",
    "\n",
    "for seqnum in specific_sequences:\n",
    "    for subnum in range(num_subjects):\n",
    "        reps = correct_trials_rep[subnum, seqnum]\n",
    "        sub_id = subnum_to_subid[subnum]\n",
    "        if sub_id in control_subjs:\n",
    "            group = 'control'\n",
    "        else:\n",
    "            group = sub_group[sub_id]\n",
    "        \n",
    "        forces = reduced_forces_global_correct_dict[subnum, seqnum]\n",
    "        for idx, force in enumerate(forces):\n",
    "            row = [sub_id, group, seqnum, reps[idx]] + force[:n_pcs_for_test].tolist()\n",
    "            df.loc[len(df)] = row\n",
    "        \n",
    "\n",
    "#include only G1 and G2\n",
    "# df = df[df['Group'] != 'control']\n",
    "    \n",
    "# MANOVA\n",
    "dependent_vars = [f'PC{i}' for i in range(1, n_pcs_for_test + 1)]\n",
    "formula = f\"{'+'.join(dependent_vars)} ~ Group + rep + seqNumb\"\n",
    "manova = MANOVA.from_formula(formula, data=df)\n",
    "# print(df)\n",
    "\n",
    "# print(manova.mv_test())\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(manova.mv_test())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
